{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('./diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>7</td>\n",
       "      <td>187</td>\n",
       "      <td>68</td>\n",
       "      <td>39</td>\n",
       "      <td>304</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.254</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>6</td>\n",
       "      <td>147</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2</td>\n",
       "      <td>127</td>\n",
       "      <td>58</td>\n",
       "      <td>24</td>\n",
       "      <td>275</td>\n",
       "      <td>27.7</td>\n",
       "      <td>1.600</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.313</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.187</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "56                7                     187              68              39   \n",
       "642               6                     147              80               0   \n",
       "395               2                     127              58              24   \n",
       "310               6                      80              66              30   \n",
       "196               1                     105              58               0   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "56       304  37.7              0.254   41             1  \n",
       "642        0  29.5              0.178   50             1  \n",
       "395      275  27.7              1.600   25             0  \n",
       "310        0  26.2              0.313   41             0  \n",
       "196        0  24.3              0.187   21             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.760\n",
      "roc-auc is 0.826\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 0.7377 - accuracy: 0.4497 - val_loss: 0.7202 - val_accuracy: 0.4375\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7261 - accuracy: 0.4688 - val_loss: 0.7100 - val_accuracy: 0.4688\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7157 - accuracy: 0.5017 - val_loss: 0.7009 - val_accuracy: 0.5156\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.5295 - val_loss: 0.6926 - val_accuracy: 0.5521\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.5503 - val_loss: 0.6851 - val_accuracy: 0.5677\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.5816 - val_loss: 0.6784 - val_accuracy: 0.5990\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6831 - accuracy: 0.6007 - val_loss: 0.6723 - val_accuracy: 0.6042\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.6163 - val_loss: 0.6668 - val_accuracy: 0.6458\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6710 - accuracy: 0.6233 - val_loss: 0.6618 - val_accuracy: 0.6615\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6657 - accuracy: 0.6267 - val_loss: 0.6573 - val_accuracy: 0.6615\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.6233 - val_loss: 0.6532 - val_accuracy: 0.6562\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.6250 - val_loss: 0.6495 - val_accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.6302 - val_loss: 0.6461 - val_accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6489 - accuracy: 0.6458 - val_loss: 0.6430 - val_accuracy: 0.6719\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6456 - accuracy: 0.6510 - val_loss: 0.6402 - val_accuracy: 0.6771\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6425 - accuracy: 0.6562 - val_loss: 0.6376 - val_accuracy: 0.6823\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.6510 - val_loss: 0.6352 - val_accuracy: 0.6927\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.6580 - val_loss: 0.6330 - val_accuracy: 0.6927\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6346 - accuracy: 0.6562 - val_loss: 0.6310 - val_accuracy: 0.6927\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6510 - val_loss: 0.6291 - val_accuracy: 0.6875\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6303 - accuracy: 0.6562 - val_loss: 0.6274 - val_accuracy: 0.6927\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6284 - accuracy: 0.6580 - val_loss: 0.6258 - val_accuracy: 0.7083\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6265 - accuracy: 0.6580 - val_loss: 0.6243 - val_accuracy: 0.7083\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6248 - accuracy: 0.6597 - val_loss: 0.6229 - val_accuracy: 0.7031\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6615 - val_loss: 0.6216 - val_accuracy: 0.6979\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6217 - accuracy: 0.6632 - val_loss: 0.6203 - val_accuracy: 0.6979\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.6649 - val_loss: 0.6192 - val_accuracy: 0.7031\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.6632 - val_loss: 0.6181 - val_accuracy: 0.7083\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6667 - val_loss: 0.6170 - val_accuracy: 0.7083\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6165 - accuracy: 0.6632 - val_loss: 0.6160 - val_accuracy: 0.7031\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.6649 - val_loss: 0.6151 - val_accuracy: 0.7031\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6142 - accuracy: 0.6649 - val_loss: 0.6142 - val_accuracy: 0.6927\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6131 - accuracy: 0.6649 - val_loss: 0.6133 - val_accuracy: 0.6927\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6121 - accuracy: 0.6667 - val_loss: 0.6124 - val_accuracy: 0.6927\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.6649 - val_loss: 0.6116 - val_accuracy: 0.6875\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6103 - accuracy: 0.6667 - val_loss: 0.6108 - val_accuracy: 0.6875\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6093 - accuracy: 0.6632 - val_loss: 0.6101 - val_accuracy: 0.6875\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6084 - accuracy: 0.6632 - val_loss: 0.6093 - val_accuracy: 0.6875\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.6632 - val_loss: 0.6086 - val_accuracy: 0.6927\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6067 - accuracy: 0.6649 - val_loss: 0.6079 - val_accuracy: 0.6927\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6649 - val_loss: 0.6072 - val_accuracy: 0.6927\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6649 - val_loss: 0.6065 - val_accuracy: 0.6875\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6044 - accuracy: 0.6649 - val_loss: 0.6059 - val_accuracy: 0.6875\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6036 - accuracy: 0.6649 - val_loss: 0.6052 - val_accuracy: 0.6979\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6684 - val_loss: 0.6046 - val_accuracy: 0.6979\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6021 - accuracy: 0.6684 - val_loss: 0.6040 - val_accuracy: 0.6979\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6684 - val_loss: 0.6034 - val_accuracy: 0.6979\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6007 - accuracy: 0.6684 - val_loss: 0.6027 - val_accuracy: 0.6979\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6684 - val_loss: 0.6021 - val_accuracy: 0.7083\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5993 - accuracy: 0.6684 - val_loss: 0.6015 - val_accuracy: 0.7083\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5987 - accuracy: 0.6701 - val_loss: 0.6010 - val_accuracy: 0.7083\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5980 - accuracy: 0.6701 - val_loss: 0.6004 - val_accuracy: 0.7083\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.6719 - val_loss: 0.5998 - val_accuracy: 0.7083\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5967 - accuracy: 0.6719 - val_loss: 0.5992 - val_accuracy: 0.7135\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.6719 - val_loss: 0.5987 - val_accuracy: 0.7135\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5954 - accuracy: 0.6736 - val_loss: 0.5981 - val_accuracy: 0.7135\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.6736 - val_loss: 0.5975 - val_accuracy: 0.7083\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5942 - accuracy: 0.6753 - val_loss: 0.5970 - val_accuracy: 0.7083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5936 - accuracy: 0.6753 - val_loss: 0.5964 - val_accuracy: 0.7083\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5930 - accuracy: 0.6771 - val_loss: 0.5959 - val_accuracy: 0.7083\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5924 - accuracy: 0.6788 - val_loss: 0.5954 - val_accuracy: 0.7083\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6823 - val_loss: 0.5948 - val_accuracy: 0.7083\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6823 - val_loss: 0.5943 - val_accuracy: 0.7083\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5906 - accuracy: 0.6840 - val_loss: 0.5937 - val_accuracy: 0.7135\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5900 - accuracy: 0.6840 - val_loss: 0.5932 - val_accuracy: 0.7135\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6840 - val_loss: 0.5927 - val_accuracy: 0.7135\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5889 - accuracy: 0.6840 - val_loss: 0.5922 - val_accuracy: 0.7135\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.6840 - val_loss: 0.5916 - val_accuracy: 0.7135\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5878 - accuracy: 0.6858 - val_loss: 0.5911 - val_accuracy: 0.7135\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5872 - accuracy: 0.6875 - val_loss: 0.5906 - val_accuracy: 0.7135\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6892 - val_loss: 0.5901 - val_accuracy: 0.7135\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5861 - accuracy: 0.6892 - val_loss: 0.5896 - val_accuracy: 0.7135\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5855 - accuracy: 0.6892 - val_loss: 0.5891 - val_accuracy: 0.7188\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6892 - val_loss: 0.5886 - val_accuracy: 0.7188\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6910 - val_loss: 0.5881 - val_accuracy: 0.7135\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5839 - accuracy: 0.6910 - val_loss: 0.5876 - val_accuracy: 0.7083\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5833 - accuracy: 0.6910 - val_loss: 0.5871 - val_accuracy: 0.7083\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5828 - accuracy: 0.6892 - val_loss: 0.5866 - val_accuracy: 0.7083\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.6892 - val_loss: 0.5861 - val_accuracy: 0.7083\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.6892 - val_loss: 0.5856 - val_accuracy: 0.7135\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6892 - val_loss: 0.5851 - val_accuracy: 0.7135\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5807 - accuracy: 0.6892 - val_loss: 0.5846 - val_accuracy: 0.7135\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5802 - accuracy: 0.6892 - val_loss: 0.5841 - val_accuracy: 0.7135\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5796 - accuracy: 0.6892 - val_loss: 0.5836 - val_accuracy: 0.7135\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5792 - accuracy: 0.6892 - val_loss: 0.5831 - val_accuracy: 0.7135\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.6892 - val_loss: 0.5827 - val_accuracy: 0.7135\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.6875 - val_loss: 0.5822 - val_accuracy: 0.7135\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.6892 - val_loss: 0.5817 - val_accuracy: 0.7135\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5771 - accuracy: 0.6892 - val_loss: 0.5812 - val_accuracy: 0.7135\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.6875 - val_loss: 0.5808 - val_accuracy: 0.7135\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.6875 - val_loss: 0.5803 - val_accuracy: 0.7135\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5756 - accuracy: 0.6892 - val_loss: 0.5798 - val_accuracy: 0.7135\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.6892 - val_loss: 0.5793 - val_accuracy: 0.7135\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5746 - accuracy: 0.6892 - val_loss: 0.5789 - val_accuracy: 0.7135\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5741 - accuracy: 0.6892 - val_loss: 0.5784 - val_accuracy: 0.7135\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5736 - accuracy: 0.6910 - val_loss: 0.5780 - val_accuracy: 0.7135\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5731 - accuracy: 0.6892 - val_loss: 0.5775 - val_accuracy: 0.7135\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.6910 - val_loss: 0.5770 - val_accuracy: 0.7135\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.6892 - val_loss: 0.5766 - val_accuracy: 0.7135\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5717 - accuracy: 0.6892 - val_loss: 0.5761 - val_accuracy: 0.7135\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5712 - accuracy: 0.6892 - val_loss: 0.5757 - val_accuracy: 0.7135\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.6927 - val_loss: 0.5752 - val_accuracy: 0.7135\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.6944 - val_loss: 0.5748 - val_accuracy: 0.7135\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5698 - accuracy: 0.6944 - val_loss: 0.5743 - val_accuracy: 0.7135\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.6944 - val_loss: 0.5739 - val_accuracy: 0.7135\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5688 - accuracy: 0.6962 - val_loss: 0.5735 - val_accuracy: 0.7135\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5684 - accuracy: 0.6979 - val_loss: 0.5730 - val_accuracy: 0.7135\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.6962 - val_loss: 0.5726 - val_accuracy: 0.7135\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.6962 - val_loss: 0.5721 - val_accuracy: 0.7135\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.6944 - val_loss: 0.5717 - val_accuracy: 0.7135\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6944 - val_loss: 0.5713 - val_accuracy: 0.7135\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5661 - accuracy: 0.6944 - val_loss: 0.5708 - val_accuracy: 0.7135\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.6944 - val_loss: 0.5704 - val_accuracy: 0.7135\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.6944 - val_loss: 0.5700 - val_accuracy: 0.7188\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5647 - accuracy: 0.6944 - val_loss: 0.5696 - val_accuracy: 0.7188\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5643 - accuracy: 0.6944 - val_loss: 0.5691 - val_accuracy: 0.7188\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.6962 - val_loss: 0.5687 - val_accuracy: 0.7188\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5634 - accuracy: 0.6962 - val_loss: 0.5683 - val_accuracy: 0.7240\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5630 - accuracy: 0.6944 - val_loss: 0.5679 - val_accuracy: 0.7240\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5625 - accuracy: 0.6944 - val_loss: 0.5675 - val_accuracy: 0.7240\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5621 - accuracy: 0.6962 - val_loss: 0.5671 - val_accuracy: 0.7240\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5616 - accuracy: 0.6962 - val_loss: 0.5667 - val_accuracy: 0.7240\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5612 - accuracy: 0.6997 - val_loss: 0.5662 - val_accuracy: 0.7240\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5608 - accuracy: 0.6979 - val_loss: 0.5658 - val_accuracy: 0.7240\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.6979 - val_loss: 0.5654 - val_accuracy: 0.7240\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.6979 - val_loss: 0.5650 - val_accuracy: 0.7240\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7014 - val_loss: 0.5646 - val_accuracy: 0.7240\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.6997 - val_loss: 0.5642 - val_accuracy: 0.7240\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7014 - val_loss: 0.5638 - val_accuracy: 0.7292\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7014 - val_loss: 0.5634 - val_accuracy: 0.7292\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7014 - val_loss: 0.5630 - val_accuracy: 0.7292\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5574 - accuracy: 0.7014 - val_loss: 0.5626 - val_accuracy: 0.7292\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5570 - accuracy: 0.7014 - val_loss: 0.5622 - val_accuracy: 0.7292\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.6997 - val_loss: 0.5619 - val_accuracy: 0.7292\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5562 - accuracy: 0.6997 - val_loss: 0.5615 - val_accuracy: 0.7344\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5558 - accuracy: 0.6997 - val_loss: 0.5611 - val_accuracy: 0.7344\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5553 - accuracy: 0.7014 - val_loss: 0.5607 - val_accuracy: 0.7344\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5549 - accuracy: 0.7014 - val_loss: 0.5603 - val_accuracy: 0.7396\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5545 - accuracy: 0.7014 - val_loss: 0.5599 - val_accuracy: 0.7396\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7031 - val_loss: 0.5596 - val_accuracy: 0.7396\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7031 - val_loss: 0.5592 - val_accuracy: 0.7396\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5533 - accuracy: 0.7031 - val_loss: 0.5588 - val_accuracy: 0.7448\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7031 - val_loss: 0.5584 - val_accuracy: 0.7448\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5525 - accuracy: 0.7031 - val_loss: 0.5581 - val_accuracy: 0.7448\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5521 - accuracy: 0.7049 - val_loss: 0.5577 - val_accuracy: 0.7448\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7031 - val_loss: 0.5573 - val_accuracy: 0.7448\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5514 - accuracy: 0.7066 - val_loss: 0.5569 - val_accuracy: 0.7448\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7049 - val_loss: 0.5566 - val_accuracy: 0.7448\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.7049 - val_loss: 0.5562 - val_accuracy: 0.7448\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7049 - val_loss: 0.5558 - val_accuracy: 0.7448\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7049 - val_loss: 0.5555 - val_accuracy: 0.7448\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5494 - accuracy: 0.7049 - val_loss: 0.5551 - val_accuracy: 0.7448\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7083 - val_loss: 0.5548 - val_accuracy: 0.7500\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7083 - val_loss: 0.5544 - val_accuracy: 0.7500\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7083 - val_loss: 0.5541 - val_accuracy: 0.7500\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5479 - accuracy: 0.7083 - val_loss: 0.5537 - val_accuracy: 0.7500\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5476 - accuracy: 0.7101 - val_loss: 0.5533 - val_accuracy: 0.7500\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5471 - accuracy: 0.7101 - val_loss: 0.5530 - val_accuracy: 0.7500\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7101 - val_loss: 0.5526 - val_accuracy: 0.7500\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5464 - accuracy: 0.7135 - val_loss: 0.5523 - val_accuracy: 0.7500\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5460 - accuracy: 0.7118 - val_loss: 0.5520 - val_accuracy: 0.7500\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7118 - val_loss: 0.5516 - val_accuracy: 0.7500\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.7118 - val_loss: 0.5513 - val_accuracy: 0.7500\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7135 - val_loss: 0.5509 - val_accuracy: 0.7500\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7135 - val_loss: 0.5506 - val_accuracy: 0.7500\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7135 - val_loss: 0.5502 - val_accuracy: 0.7500\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5439 - accuracy: 0.7135 - val_loss: 0.5499 - val_accuracy: 0.7500\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5435 - accuracy: 0.7153 - val_loss: 0.5496 - val_accuracy: 0.7500\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5432 - accuracy: 0.7153 - val_loss: 0.5492 - val_accuracy: 0.7500\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7153 - val_loss: 0.5489 - val_accuracy: 0.7500\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5424 - accuracy: 0.7118 - val_loss: 0.5486 - val_accuracy: 0.7500\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.7118 - val_loss: 0.5482 - val_accuracy: 0.7500\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5417 - accuracy: 0.7101 - val_loss: 0.5479 - val_accuracy: 0.7500\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7101 - val_loss: 0.5476 - val_accuracy: 0.7500\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7101 - val_loss: 0.5473 - val_accuracy: 0.7448\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.7118 - val_loss: 0.5469 - val_accuracy: 0.7448\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5404 - accuracy: 0.7118 - val_loss: 0.5466 - val_accuracy: 0.7448\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7118 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5397 - accuracy: 0.7118 - val_loss: 0.5460 - val_accuracy: 0.7448\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.7118 - val_loss: 0.5457 - val_accuracy: 0.7396\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5390 - accuracy: 0.7135 - val_loss: 0.5453 - val_accuracy: 0.7344\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5386 - accuracy: 0.7153 - val_loss: 0.5450 - val_accuracy: 0.7344\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5383 - accuracy: 0.7153 - val_loss: 0.5447 - val_accuracy: 0.7344\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5380 - accuracy: 0.7153 - val_loss: 0.5444 - val_accuracy: 0.7344\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.7153 - val_loss: 0.5441 - val_accuracy: 0.7344\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5373 - accuracy: 0.7153 - val_loss: 0.5438 - val_accuracy: 0.7344\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5370 - accuracy: 0.7153 - val_loss: 0.5435 - val_accuracy: 0.7344\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5366 - accuracy: 0.7135 - val_loss: 0.5432 - val_accuracy: 0.7344\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7153 - val_loss: 0.5429 - val_accuracy: 0.7344\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.7170 - val_loss: 0.5426 - val_accuracy: 0.7344\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5357 - accuracy: 0.7170 - val_loss: 0.5423 - val_accuracy: 0.7344\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5353 - accuracy: 0.7170 - val_loss: 0.5420 - val_accuracy: 0.7344\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.7188 - val_loss: 0.5417 - val_accuracy: 0.7344\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5347 - accuracy: 0.7188 - val_loss: 0.5414 - val_accuracy: 0.7344\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7188 - val_loss: 0.5411 - val_accuracy: 0.7344\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.7222 - val_loss: 0.5408 - val_accuracy: 0.7344\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5338 - accuracy: 0.7222 - val_loss: 0.5405 - val_accuracy: 0.7344\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7222 - val_loss: 0.5402 - val_accuracy: 0.7396\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5331 - accuracy: 0.7240 - val_loss: 0.5399 - val_accuracy: 0.7448\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5328 - accuracy: 0.7222 - val_loss: 0.5396 - val_accuracy: 0.7448\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)\n",
    "y_pred_class_nn_1 = np.argmax(y_pred_prob_nn_1, axis =1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3602429 ],\n",
       "       [0.52867776],\n",
       "       [0.2985025 ],\n",
       "       [0.4372256 ],\n",
       "       [0.23644459],\n",
       "       [0.37091148],\n",
       "       [0.19966549],\n",
       "       [0.40967616],\n",
       "       [0.64172894],\n",
       "       [0.31555378]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.797\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8bElEQVR4nO3dd5xU5dn/8e9FV4SlClIEzYKIaBaziPFB3dgNPho1+gNUNI/GFI0KUhUQREBEQU00cW0EDfYSiKjYVhQLIK7SRGlSBKQtHbbdvz9mIMO6ZXZ3Zu4pn/frxcspZ2e+c88411zn3Occc84JAADEjxq+AwAAgENRnAEAiDMUZwAA4gzFGQCAOENxBgAgzlCcAQCIMxRnpBwzO8zMppvZdjN7yXeeVGVmk83snuDl081saZh/d52ZfRzddH5V9BrNLMfMbohlJsQWxTnJmdkqM9trZrvMbEPwC/GIEsucZmbvm9nOYMGabmadSyzT0MweNLPVwcdaHrzerIznNTO7xcwWmtluM1trZi+Z2YnRfL1h+q2kFpKaOueuqO6DmVmWmTkze7TE7R+b2XXBy9cFlxlUYpm1ZpZV3QxhZAz9HGwM/RyEftGHvJbXSvz9z4O355S43cxshZktrk4+59xHzrnjqvMY4UiFwo7kQHFODf/rnDtCUoakrpKGHrjDzH4paaakf0tqJekYSV9Jmm1mxwaXqSPpPUknSLpAUkNJv5S0RdIpZTznQ5JulXSLpCaSOkp6XVLPyoY3s1qV/ZsKtJP0rXOuMIJZdku6xszal/PnWyUNMrMGlX3eCDnwOThZUqakYWUst0nSL82sacht10r6tpRlz5B0pKRjzaxbJMMmsyh8ppFkKM4pxDm3QdLbChTpA+6TNMU595BzbqdzbqtzbpikzySNDC7TV9LRki51zi12zhU75350zo12zs0o+Txm1kHSTZJ6O+fed87td87tcc79yzl3b3CZQ1bLlexogl3aTWb2naTvzOzvZnZ/ief5t5n1D15uZWavmNkmM1tpZreUNgZmNkrSCEn/L9hFXm9mNcxsmJl9b2Y/mtkUM0sLLt8+mOV6M1st6f0yhjdP0mRJd5VxvyQtkfSppP7lLBOaNS2YZVMw2zAzqxG877pgZ36/mW0LvuYLw3lc59w6SW9K6lLGIvkK/JDqFXyumpL+n6R/lbLstQr8sJsRvFze6+lqZvODa2hekFQv5L4sM1sbcn1IcO3MTjNbbGaX/vTh7G/BNT3fmNnZIXekmdmTZrbezNaZ2T1mVtPMjpf0DwV+eOwys7zg8nWD47g6uFbhH2Z2WPC+Zmb2HzPLM7OtZvbRgfeglNfnLLC2aIWZbTazCSXer9lmNsnMtkgaWd77W9FrLOW5/8/MlgQ/C2+bWbsSuf5sZt8Fx3O0mf3MzD4xsx1m9qIFfoAjjlCcU4iZtZF0oaRlweuHSzpNUmnbXV+UdG7w8jmS3nLO7Qrzqc6WtNY5N6d6ifUbSd0ldZb0nAIF1STJzBpLOk/S88EvtOkKdPytg89/m5mdX/IBnXN3SRor6QXn3BHOuSclXRf89ytJx0o6QtLfSvzpmZKOl/STxwwxRtLlZlbe6tnhwWxNylnmgL9KSgtmOlOBH0m/C7m/u6Slkpop8CPryQPjUx4zayvp15K+LGexKcHnkwKveaGkH0o8zuEKbCL4V/Bfr7K+5IO3vy7pGQXWpLwk6fJynn+5pNMVeP2jJD1rZkeF3N89uEwzBX4QvRoyppMlFUpKV2BN0XmSbnDOLZH0R0mfBt/7RsHl71VgzU5G8G9aK/ADTpJul7RWUnMFNoXcIam8Yx5fqsBaiZMlXSLp/0pkXhF8nDEK7/0t6zUeZGaXBHNdFsz5kQL/v4Q6X9IvJJ0qaZCkbElXS2qrwI+03uW8JnhAcU4Nr5vZTklrJP2o/3Z3TRT4DKwv5W/WK/ClIElNy1imLJVdvizjgp38XgW+cJwCX9hSoCh86pz7QVI3Sc2dc3c75/KdcyskPa5g5xeGqyRNdM6tCP4AGapAoQld9TjSObc7mKVUwTUT/5B0dznL5Ep6R9Lg8gIFu9VekoYG12iskvSApGtCFvveOfe4c65I0j8lHaXAF39ZXg92ix9L+lCBHyll5fxEUpPgD42+ChTrki6TtF+BzSJvSKqtsjdbnBq8/0HnXIFz7mVJc8t5/peccz8E19K8IOk7HboJ5ceQx3pBgR8pPc2shQI/PG4Lvl8/SpqkMj4LwR8zN0rqF/ys7VRgXA4sX6DAuLYLPtdHrvwTEowPPs5qSQ/q0KL3g3Pur8HNKfmq+P0t9TWW8px/VOD/lSXBxx4rKSO0e5Z0n3Nuh3NukQI/tGYGP+/bFViL0rWc1wQPKM6p4TfOuQaSsiR10n+L7jZJxQp8+ZR0lKTNwctbylimLJVdvixrDlwIfiE+r/9+2fXRf1eztpPUKrjqMS9YgO5Q+YUqVCtJ34dc/15SrRJ/v0bhGS/pfDP7eTnLjJD0p2AhKUszBYpZyVytQ65vOHDBObcnePGQyX4l/MY518g518459+fyfmgEPSPpZgXWKLxWyv3XSnrROVfonNsn6RWVvWq7laR1JQrb92UsKzPra2a5Ie9nF/33c6syHquVAp+F2pLWh/ztYwpsFy9Nc0mHS/oiZPm3grdL0gQF1jTNDK6uHlJW5qDQz8mBTKXdF877W9ZrLKmdpIdC8m+VZCUea2PI5b2lXC/vcwMPKM4pxDn3oQKr/O4PXt+twDbQ0mYsX6nAJDBJeleBglM/zKd6T1IbM8ssZ5ndCnwpHtCytMglrj8n6bfBjqC7AsVACnzprQwWngP/Gjjnfh1m3h8U+II74GgFVouGfoGFdfo259wWBTqm0eUs842kVyXdWc5DbVagayuZa104OSLkGUl/ljQjpPhLOriJ5CxJV1tgL4ANCqzN+LWVPoN/vaTWJVa7H13akwbf38cV+GHQNLj6eaECBeeA0h7rBwU+C/slNQv5LDR0zp0QXK7k+7hZgeJ0QsjyacGJcwp2tbc7546VdLGk/uVt+1VgNXHJTAeEPnc4729Zr7GkNZL+UOLzf1hw7QcSFMU59Two6dyQzm6IpGuDE1kamFljC+x7+ksFtvVJgS/pNZJeMbNOFphA1dTM7jCznxRA59x3kh6V9JwFJvrUMbN6ZtYrpPPIlXSZmR1uZumSrq8ouHPuSwW+1J6Q9LZzLi941xxJO81ssAX2Ya5pZl0s/NnDz0nqZ2bHWGD3ogPbpCs9mztoogLb8o8vZ5lRCmxfbFTancFV1S9KGhN8X9opMJHs2SpmqjTn3EoFtoWW9iPiGgVmbx+nwLbaDAW2265V6dsvP1XgB88tZlbbzC5T2TP96ytQyDZJkpn9Tj+dvHZkyGNdocBYz3DOrVdgNfsDFtj9r0Zw8tOZwb/bqMAPxzrB11iswA+BSWZ2ZPD5Wh+Yr2BmF5lZerBIbpdUpMDaprIMDP4/1FaBvRVeKG2hMN/fUl9jKQ/3D0lDzeyEYOa04PJIYBTnFOOc26TA9sMRwesfKzBZ5DIFupvvFdj+1CNYZOWc26/ApLBvFNheukOBgthM0udlPNUtCkyqekSBmczLFZgsMz14/yQFtrttVGB7aWkzgUszNZhlashrKpJ0kQIFYqX+W8DTwnzMpxT4ATIr+Pf7JP0lzL/9CefcDgUmaJU56StY+J5RoBCV5S8KrGFYocB24qnBrDHjnPs4uF2/pGslPeqc2xD6T4FC8ZNV2865fAU+Y9cpsNr1/ymw9qC051yswPbXTxX4fJwoaXaJxT6X1EGB93qMpN8G11pIgW3kdSQtVmDTzcv672aW9yUtkrTBzA5sthmswKrrz8xshwJrig5M6usQvL4rmOdR59wHpeUO+rekLxT48fmGpCfLWbai97e813iQc+41BTanPB/Mv1CBiZ9IYFb+3AYAQDjMzEnq4Jxb5jsLEh+dMwAAcYbiDABAnGG1NgAAcYbOGQCAOENxBgAgzlR4ZhQze0qB3VR+dM795ED5wf3/HlLgkHl7JF3nnJtf0eM2a9bMtW/f/uD13bt3q379cI9xgcpifKOL8Y0exja6GN/oKTm2X3zxxWbnXPNy/uSgcE5bNlmB/VVLO7auFNifrkPwX3dJfw/+t1zt27fXvHnzDl7PyclRVlZWGHFQFYxvdDG+0cPYRhfjGz0lx9bMyjxkbUkVrtZ2zs1S4KABZblEgVMOOufcZ5IalTh7DAAAqIRInPC7tQ49oPva4G2ROCsRAABxKTs7W1OnTi3z/mbNmlV5rUQkinPYzOxGBU7PphYtWignJ+fgfbt27TrkOiKL8Y0uxjd6GNvoYnyr7tFHH9WyZcuUnp5+yO3OOW3cuFEZGRlVHttIFOd1OvRMLG1UxplznHPZCpzkW5mZmS70FwXbPaKL8Y0uxjd6GNvoYnyrrlGjRsrMzDykABcXF2vJkiWqU6eO1q1bV+WxjcSuVNMk9bWAUyVtD54ZBgCAlOGc09ChQ+WcU4cOHar1WOHsSvWcpCxJzcxsraS7FDhJuJxz/1DgFGa/VuCsLnsUOA0eAAApo6CgQLNnz9aQIUPUuHHjaj9ehcXZOVfauVlD73eSbqp2EgAAEtTo0aPVt2/fiBRmKcYTwgAAKE9FM6DjSW5urk466SRNnTpVd911l2rWrBmxx+bwnQCAuDF16lTl5ub6jhGWjIwMtWzZUj169IhoYZbonAEAcaY6uyDFyu7du/XYY4+pf//+UXl8OmcAACrp9ddfV58+faL2+BRnAADCtH37dg0ePFh9+vRRy5Yto/Y8FGcAAMKQn5+vOXPmaPDgwQqckDF6KM4AAFRg8+bN6tevn84880w1adIk6s/HhDAAiIJE2SUoLy9PjRo18h3joNzcXGVkZPiOcYgtW7bo+++/17hx41SnTp2YPCedMwBEQSLtEhRPMjIyojrRqrLWr1+vESNGqFOnTmrYsGHMnpfOGQCiJBF2CeLEF2Vbu3attm3bpgkTJujwww+P6XPTOQMAUML69et13333qUOHDjEvzBKdMwAAh1i+fLl27typCRMmqG7dul4y0DkDABC0Y8cO/f3vf9cJJ5zgrTBLdM4AEJWZ1fE46xjlW7x4sTZu3KgJEyZEfT/mitA5A0h50ZhZHW+zjlG+wsJCvfLKKzrjjDO8F2aJzhkAJCXGzGpEx/z587VixQoNHz7cd5SD6JwBACnLOae5c+fq8ssv9x3lEHTOAICUNHv2bC1cuFB/+MMffEf5CTpnAEDK2b17t7Zt26Ybb7zRd5RS0TkDSEqVmYHNzOrU8u6772rRokW69dZbfUcpE50zgKRUmRnYzKxOHStXrlTTpk3jujBLdM4AkhgzsBHqP//5j1avXq0///nPvqNUiOIMAEh6H3/8sbp166aLLrrId5SwsFobAJDUZsyYoWXLlqlFixa+o4SNzhkAkLReffVVnXfeeTriiCN8R6kUOmcAQFKaNWuW8vPzE64wSxRnAEASevLJJ9WlSxf16tXLd5QqoTgDAJLKwoUL1axZMzVp0sR3lCqjOAMAksZDDz2kww8/XJdcconvKNVCcQYAJIU1a9aoc+fOOvbYY31HqTaKMwAgoTnndO+992rz5s0699xzfceJCHalAhBXSh4TOy8vT40aNar043C87NTgnNPatWv1q1/9Sl27dvUdJ2LonAHElcocE7s8HC87+TnnNGrUKG3YsEHdu3f3HSei6JwBxJ3QY2Ln5OQoKyvLax7En+LiYi1atEhXX3210tPTfceJODpnAEBCcc5p2LBhKi4uTsrCLNE5AwASSGFhoXJycjR48GClpaX5jhM1dM4AgIQxduxYtW3bNqkLs0TnDCBKSs66DhezrFGa/Px8vfDCCxo2bJhq1Ej+vjL5XyEAL6o665pZ1ijN448/rtNPPz0lCrNE5wwgikJnXQNVsXfvXv3tb3/TwIEDfUeJqdT4CQIASDjOOU2fPl1XXXWV7ygxR3EGAMSdnTt3auDAgfrtb3+rVq1a+Y4TcxRnAEBc2bdvn7744gsNGTIkZbYxl5SarxoAEJe2bt2q/v3769RTT1WzZs18x/GGCWFACqjqbk3VwS5RqKwtW7Zo9erVGjdunOrVq+c7jld0zkAKiNTJJCqDXaJQGRs3btSIESOUnp6e9AcYCQedM5Ai2K0J8eqHH37Q5s2bdd9996l+/fq+48QFOmcAgDebNm3Svffeqw4dOlCYQ9A5AwC8WLVqlbZs2aIJEyaobt26vuPEFTpnAEDM7dmzR3/961914oknUphLQecMJInyZmQzcxrxZOnSpVq1apXuv/9+mZnvOHGJzhlIEuXNyGbmNOJFUVGRXn75ZZ199tkU5nLQOQNJhBnZiGdfffWVFi5cqDvvvNN3lLhH5wwAiLri4mLNnTtXvXv39h0lIdA5AwCi6rPPPtPcuXP1l7/8xXeUhEHnDACImp07d2rbtm26+eabfUdJKHTOAICoyMnJ0bx58zRgwADfURIOnTMAIOKWLVumJk2aUJiriOIMAIiot956SzNmzNBJJ53kO0rCYrU2ACBiZs2apZNPPlkXXHCB7ygJjc4ZABARM2fO1NKlS3XkkUf6jpLw6JwBANX26quv6pxzztF5553nO0pSoDgDCYTjZyMeff7559q7d68aNmzoO0rSYLU2kEA4fjbizdNPP6327dvrqquu8h0lqdA5AwmG42cjXnz33Xdq2LChWrRo4TtK0qFzBgBU2iOPPKKioiJdfvnlvqMkJYozAKBSNmzYoPT0dHXq1Ml3lKRFcQYAhMU5p/vvv1+rV6/W+eef7ztOUmObMxAh5c2kjhRmZMMX55zWrVunHj166JRTTvEdJ+nROQMRUt5M6khhRjZ8cM7pnnvu0Zo1a3Tqqaf6jpMS6JyBCGImNZKNc04LFixQnz599LOf/cx3nJRB5wwAKNPIkSNVWFhIYY4xOmcAwE8UFRXp3Xff1YABA9SgQQPfcVIOnTMA4Cfuu+8+tW3blsLsCZ0zAOCggoICPfvssxo8eLBq1KB/84XiDFRCWbtL5eXladWqVezmhIQ3efJknXXWWRRmzxh9oBI48QSS1b59+zRmzBjdcMMNTP6KA2F1zmZ2gaSHJNWU9IRz7t4S9x8t6Z+SGgWXGeKcmxHZqEB8KG13qZycHGVlZXnJA1SXc05vvvmmrr32WpmZ7zhQGJ2zmdWU9IikCyV1ltTbzDqXWGyYpBedc10l9ZL0aKSDAgAib+/everfv7/+93//V23atPEdB0HhrNY+RdIy59wK51y+pOclXVJiGSfpwFm20yT9ELmIAIBo2Lt3r5YtW6ahQ4eqVi2mIMWTcN6N1pLWhFxfK6l7iWVGSpppZn+RVF/SOaU9kJndKOlGSWrRosUhqwZ37drFkZWiiPGNjLy8PEn6yVgyvtHD2EbHrl279Pjjj+vqq6/W4sWLtXjxYt+Rkk51PruR+qnUW9Jk59wDZvZLSc+YWRfnXHHoQs65bEnZkpSZmelCt9GxzS66GN+qC52hfWBGdsmxZHyjh7GNvK1bt2rNmjWaPHmyvvrqK8Y3Sqrz2Q1ntfY6SW1DrrcJ3hbqekkvSpJz7lNJ9SQ1q1IiIM6EztBmRjYS3ebNmzV8+HC1b99ejRs39h0HZQinc54rqYOZHaNAUe4lqeS302pJZ0uabGbHK1CcN0UyKOATJ7RAMtiwYYM2btyoe++9lyN/xbkKO2fnXKGkmyW9LWmJArOyF5nZ3WZ2cXCx2yX93sy+kvScpOuccy5aoQEAlbNt2zaNHj1a6enpFOYEENY25+A+yzNK3DYi5PJiSf8T2WgAgEhYvXq1fvjhB02cOFF169b1HQdh4AhhAJDE9u/fr4ceekhdu3alMCcQdmxDSirrGNmlyc3N5ZjZSEjfffedli5dqvvvv58jfyUYOmekpPKOkV0SM7SRiJxzevnll3XBBRdQmBMQnTNSFjOwkawWLlyoefPmaejQob6joIronAEgiRQXF2vevHnq27ev7yioBjpnAEgS8+bN06xZs9S/f3/fUVBNdM4AkAS2b9+urVu3ql+/fr6jIALonJHQKjPrOhQzsJFMPvroI82ePVtDhgzxHQURQueMhFaZWdehmIGNZLF06VI1adJEgwcP9h0FEUTnjITHrGukqnfffVdff/0125iTEMUZABLQrFmzdNJJJ+mcc87xHQVRwGptAEgwOTk5Wrx4sY488kjfURAldM4AkEBee+01ZWVlKSsry3cURBHFGXGvvBnZzLpGKsnNzdWOHTvUuHFj31EQZazWRtwrb0Y2s66RKp555hk1bdpU1157re8oiAE6ZyQEZmQjla1evVp169ZV27ZtfUdBjNA5A0Ace+yxx7Rt2zZdeeWVvqMghijOABCnNm3apKOPPlo///nPfUdBjFGcASAOTZo0SUuXLtWFF17oOwo8YJszvKjMMbGZkY1U4pzTunXrdNppp6l79+6+48ATOmd4UZljYjMjG6nCOadx48Zp5cqVFOYUR+cMb5iBDfyXc065ubnq3bu3jjnmGN9x4BmdMwDEgXvuuUeFhYUUZkiicwYAr4qLizVjxgz1799f9evX9x0HcYLOGQA8mjhxotq1a0dhxiHonAHAg8LCQj399NO6/fbbZWa+4yDO0DkDgAfPPvuszjzzTAozSkXnDAAxtH//fo0fP17Dhw+nMKNMdM4AECPOOb377ru69tprKcwoF8UZAGJgz5496tevn84991y1a9fOdxzEOYozAETZ3r17tWDBAg0ZMkR16tTxHQcJgOIMAFG0Y8cODRgwQJ06dVLLli19x0GCYEIYYqLkiS44mQVSwbZt27R69WrdfffdSktL8x0HCYTOGTFR8kQXnMwCyW7r1q0aNmyY2rVrp6ZNm/qOgwRD54yY4UQXSBWbNm3SunXrNG7cODVs2NB3HCQgOmcAiKCdO3dq1KhRSk9PpzCjyuicASBC1q1bp5UrV2rixInMyka10DkDQAQUFhbqoYceUmZmJoUZ1UbnDADVtGLFCn311Ve67777fEdBkqBzBoBqcM7plVde0UUXXeQ7CpIInTMAVNGSJUv00UcfaeDAgb6jIMnQOQNAFRQVFemLL77Q9ddf7zsKkhCdMwBU0pdffqmZM2dq8ODBvqMgSdE5A0AlbNu2Tdu2bWNVNqKKzhk/UfI42JHAsbSRDD755BO9//77GjZsmO8oSHJ0zviJksfBjgSOpY1Et2TJEjVu3Fh33nmn7yhIAXTOKBXHwQb+68MPP9ScOXM0YMAAmZnvOEgBFGcAKMeHH36oTp066cwzz/QdBSmE1doAUIZPPvlECxYsUIsWLXxHQYqhcwaAUvz73//WaaedptNOO813FKQgOmcAKGHx4sXavHmzmjdv7jsKUhTFGQBC/Otf/1LdunU58he8ojgDQNCGDRtUo0YN/exnP/MdBSmO4gwAkp544gmtWbNGvXv39h0FoDgDwNatW3XUUUepW7duvqMAkpitDSDFPfzwwzrxxBPVs2dP31GAgyjOAFLW2rVr1b17d3Xv3t13FOAQrNYGkJLuvfdefffddxRmxCU6ZwApxTmnL774Qn369NHRRx/tOw5QKjpnACll/PjxKigooDAjrtE5A0gJxcXFmj59um699VYddthhvuMA5aJzBpASHnnkEbVr147CjIRA5wwgqRUVFenxxx/XzTffzLmYkTDonCFJys7OVlZWlrKyspSbm+s7DhAxL7zwgrKysijMSCgUZ0iSpk6derAoZ2RkqE+fPn4DAdWUn5+vkSNHqlevXurUqZPvOEClsFobB2VkZCgnJ8d3DKDaiouL9eGHH+raa69VjRr0IEg8fGoBJJW9e/eqX79+6tGjh4455hjfcYAqoXMGkDT27NmjJUuWaNCgQczKRkKjcwaQFHbu3KmBAweqffv2at26te84QLXQOaeI6dOna+TIkWXen5ubq4yMjJjlASJp+/btWrVqlUaOHKmmTZv6jgNUG51zinjvvffK3UWKGdpIVHl5eRo6dKjatm2r5s2b+44DRASdcwphNjaSzebNm7V69WqNGzdOaWlpvuMAEUPnDCAh7d27VyNHjlSHDh0ozEg6dM4AEs769eu1ZMkSTZo0SbVr1/YdB4g4OmcACaW4uFgPPvigTj31VAozkhadc4LLzs7W1KlTK1xu2bJlyszMjEEiIHpWrVqlzz77TOPHj/cdBYiqsDpnM7vAzJaa2TIzG1LGMlea2WIzW2RmFVcLREToMbHLk56ezmxsJLxXX31Vl112me8YQNRV2DmbWU1Jj0g6V9JaSXPNbJpzbnHIMh0kDZX0P865bWZ2ZLQC46fCmYWdk5OjrKysmOQBIm3p0qV655131L9/f99RgJgIp3M+RdIy59wK51y+pOclXVJimd9LesQ5t02SnHM/RjYmgFRVVFSk+fPn649//KPvKEDMhFOcW0taE3J9bfC2UB0ldTSz2Wb2mZldEKmAAFLX119/ralTp6p3796qVYspMkgdkfq015LUQVKWpDaSZpnZic65vNCFzOxGSTdKUosWLQ5ZFbtr1y4OkFEFeXl5klTh2DG+0cX4Rt727du1cuVKXXLJJYxtFPHZjZ7qjG04xXmdpLYh19sEbwu1VtLnzrkCSSvN7FsFivXc0IWcc9mSsiUpMzPThW4DZZto1TRq1EiSKhw7xje6GN/ImjNnjj744AONGjWKsY0yxjd6qjO24azWniupg5kdY2Z1JPWSNK3EMq8r0DXLzJopsJp7RZUSAUhpixYtUlpaWrknagGSXYXF2TlXKOlmSW9LWiLpRefcIjO728wuDi72tqQtZrZY0geSBjrntkQrNIDkNHv2bE2bNk0dO3aUmfmOA3gT1jZn59wMSTNK3DYi5LKT1D/4DwAqbdasWerYsaNOO+00CjNSHofvBODdvHnzNH/+fLVs2ZLCDIjiDMCz6dOnq1WrVrrtttt8RwHiBjsOJoDyjp+dm5urjIyM2AYCImT58uVav369WrVq5TsKEFfonBNAecfPzsjI4JjZSEgvvPCC9u/frxtvvNF3FCDu0DkniHCOnw0kii1btqiwsFCdO3f2HQWISxRnADE1efJkpaen66qrrvIdBYhbrNYGEDPbt29X8+bN1aNHD99RgLhG5wwgJh599FGlp6erZ8+evqMAcY/iDCDq1qxZo27duqlbt26+owAJgeLsSXm7R5XE7lJIZA888IBOOukknXvuub6jAAmDbc6elLd7VEnsLoVE5JzT559/rl69elGYgUqic/aI3aOQzCZOnKhTTz1VrVu39h0FSDgUZwAR5ZzTa6+9pptuukn16tXzHQdISKzWBhBR2dnZateuHYUZqAY6ZwARUVRUpEcffVQ333wzZ5YCqonOGUBEvPrqqzrrrLMozEAEUJwBVEtBQYGGDx+uSy+9VCeccILvOEBSoDgDqLLi4mLNnj1b1157rWrVYisZECkUZwBVsm/fPvXr10+/+MUvlJ6e7jsOkFT4qQug0vbu3aulS5dqwIABatCgge84QNKhcwZQKbt379bAgQPVqlUrtW3b1nccICnROQMI286dO7Vy5UoNHz5cRx55pO84QNKicwYQlp07d2rIkCFq1aqVWrRo4TsOkNTonAFUaOvWrVqxYoXGjh2rtLQ033GApEfnDKBc+fn5GjFihDp06EBhBmKEzhlAmTZu3Kjc3Fw9+OCD7McMxBCdM4BSOef08MMPq0ePHhRmIMb4Pw7AT6xZs0Y5OTkaM2aM7yhASqJzBvATr7/+uq644grfMYCURecM4KDly5dr2rRp6tevn+8oQEqjcwYgKXB2qfnz5+vmm2/2HQVIeXTOALRo0SK9+OKLGjVqlO8oAETnDKS8H3/8UXl5eRoxYoTvKACC6JxjJDs7W1OnTj14PTc3VxkZGf4CAZK++OILvfbaaxo9erTMzHccAEF0zjEydepU5ebmHryekZGhPn36+AuElLdw4UI1aNCAwgzEITrnGMrIyFBOTo7vGIDmzJmjmTNn6s4776QwA3GIzhlIMR999JHatGlDYQbiGMUZSCFff/215syZo1atWlGYgThGcQZSxIwZM5SWlqbbb7/ddxQAFaA4R1F2draysrKUlZV1yGQwINbWrFmjVatWqV27dr6jAAgDxTmKQmdoMzsbvrz88svasmWL/vznP/uOAiBMzNaOMmZow6ft27dr79697FMPJBiKM5CknnnmGbVu3VrXXHON7ygAKonV2kAS2rFjh5o2baqzzjrLdxQAVUDnDCSZxx57TG3atFHPnj19RwFQRRRnIIl8//33yszM1C9+8QvfUQBUA8W5mkqe0CIUJ7dALD300EPq2LGjLrzwQt9RAFQTxbmaDuwuVVoRZvcpxIJzTp988omuvPJKHXXUUb7jAIgAinMEsLsUfHr44YeVkZFBYQaSCMUZSFDOOb300kv64x//qLp16/qOAyCC2JUKSFBPP/202rVrR2EGkhCdM5BgiouL9fDDD+vWW2/lzFJAkqJzBhLMf/7zH5111lkUZiCJUZyBBFFYWKjhw4fr/PPP10knneQ7DoAoojgDCaCoqEhz5szRNddcwzZmIAVQnIE4l5+frwEDBuj4449Xx44dfccBEANMCAPi2L59+/Ttt9/qtttuU+PGjX3HARAjdM5AnNqzZ48GDhyo5s2bq127dr7jAIihlO2cyzsmdmVw/GxEw+7du7V8+XLdcccdHPkLSEEp2zkfOCZ2dXH8bETa7t27NWjQILVs2ZLCDKSolO2cJY6JjfiTl5enpUuXauzYsUpLS/MdB4AnKds5A/GmsLBQI0aMUMeOHSnMQIpL6c4ZiBebNm3S559/rkmTJqlmzZq+4wDwjM4Z8Mw5p7/97W/KysqiMAOQlEKdc8nZ2cyyRjxYt26d3n77bY0aNcp3FABxJGU655Kzs5llDd+cc5o2bZp69+7tOwqAOJMynbPE7GzEj5UrV+qFF17QkCFDfEcBEIdSpnMG4sX+/fuVm5ur/v37+44CIE5RnIEYWrJkiUaNGqVLL71UderU8R0HQJyiOAMxsmHDBm3fvl2jR4/2HQVAnKM4AzGQm5urhx56SKeccgq7SwGoEMUZiLKFCxeqfv36GjNmjGrU4H85ABXjmwKIovnz5+vll19Weno6hRlA2Pi2AKJk9uzZatasme666y6Zme84ABIIxRmIgm+++UYff/yx2rZtS2EGUGkUZyDCZs6cqRo1amjw4MEUZgBVElZxNrMLzGypmS0zszIPaWRml5uZM7PMyEUEEsfGjRv1zTffqGPHjr6jAEhgFRZnM6sp6RFJF0rqLKm3mXUuZbkGkm6V9HmkQwKJ4PXXX9eqVat0yy23+I4CIMGF0zmfImmZc26Fcy5f0vOSLilludGSxkvaF8F8QELYu3evduzYoe7du/uOAiAJhFOcW0taE3J9bfC2g8zsZEltnXNvRDAbkBCee+45LViwQH379vUdBUCSqPZZqcyshqSJkq4LY9kbJd0oSS1atDjkDFG7du2K6hmj8vLyJCllz0oV7fFNVbt379b333+vLl26ML5Rwmc3uhjf6KnO2IZTnNdJahtyvU3wtgMaSOoiKSc4M7WlpGlmdrFzbl7oAznnsiVlS1JmZqbLyso6eF9OTo5Cr0dao0aNJCmqzxHPoj2+qeipp55SkyZNNGTIEMY3ihjb6GJ8o6c6YxtOcZ4rqYOZHaNAUe4lqc+BO51z2yU1O3DdzHIkDShZmIFksmLFCp188snKyMjwHQVAEqpwm7NzrlDSzZLelrRE0ovOuUVmdreZXRztgNWRnZ2trKwsZWVlKTc313ccJIlHHnlEixYtojADiJqwtjk752ZImlHithFlLJtV/ViRMXXqVOXm5iojI0MZGRnq06dPxX8ElOOjjz7SFVdcoSOPPNJ3FABJrNoTwuJdRkYGkx0QEX//+9913HHHUZgBRF3SF2egupxzev7553XDDTeodu3avuMASAEcWxuowNSpU9W+fXsKM4CYoXMGylBcXKwHH3xQt956q2rWrOk7DoAUklTFOTs7W1OnTj14/cBkMKAqZs6cqV/96lcUZgAxl1SrtQ/Mzj6AGdqoiqKiIg0bNkxnnHGGunbt6jsOgBSUVJ2zxOxsVE9RUZHmz5+vq666SocffrjvOABSVFJ1zkB1FBQUaODAgWrXrp2OP/5433EApLCk65yBqti/f7++++473XzzzezHDMA7OmekvH379mngwIFq1KiRjj32WN9xAIDOGaltz549WrZsmYYMGaJWrVr5jgMAkuickcL27dunQYMG6cgjj6QwA4grdM5ISTt27NCCBQs0duxYNWzY0HccADgEnTNSTnFxsYYPH65OnTpRmAHEJTpnpJQtW7Zo1qxZmjRpkmrU4LcpgPjEtxNSyqOPPqqzzz6bwgwgriV85xx6PG2OpY2ybNiwQf/+9781fPhw31EAoEIJ3z6EHk+bY2mjNM45TZ8+Xddcc43vKAAQloTvnCWOp42yff/995oyZQodM4CEkvCdM1CWffv26euvv9agQYN8RwGASqE4Iyl9++23GjFihC666CLVrVvXdxwAqBSKM5LODz/8oO3bt2vs2LEyM99xAKDSEm6bc+jsbIkZ2jjUggUL9Oyzz2rs2LGqWbOm7zgAUCUJ1zmHzs6WmKGN/1q4cKHq1auncePGUZgBJLSE65wlZmfjpxYuXKgXX3xRI0eO5AAjABIe32JIeJ9++qnq16+vUaNGUZgBJAW+yZDQVqxYoQ8++EDt27dn8heApEFxRsJ67733tGfPHg0dOpTCDCCpUJyRkLZu3aqFCxeqS5cuFGYASSchJoRxcguE+s9//qO0tDTdeuutvqMAQFQkROfMyS1wwL59+7R161adfvrpvqMAQNQkROcssfsUpBdffFH16tVT3759fUcBgKhKmOKM1LZjxw41bNhQF1xwge8oABB1FGfEvX/+8586/PDDdcUVV/iOAgAxQXFGXPvuu+908skn68QTT/QdBQBiJiEmhCE1PfbYY1q8eDGFGUDKoXNGXPrggw90+eWXq1mzZr6jAEDM0Tkj7jzxxBMqKCigMANIWXTOiBvOOT377LO67rrrVKsWH00AqYvOGXHj5ZdfVvv27SnMAFIe34LwzjmniRMn6pZbblHt2rV9xwEA7+KyOIceS1vieNrJ7oMPPtCZZ55JYQaAoLhcrR16LG2J42knq+LiYg0bNkyZmZnKzMz0HQcA4kZcds4Sx9JOdkVFRVqwYIF69eqlhg0b+o4DAHElLjtnJLeCggINHjxYzZs3V5cuXXzHAYC4E7edM5JTfn6+li1bpj/84Q9q3bq17zgAEJfonBEz+/fv16BBg3T44YerQ4cOvuMAQNyic0ZM7N27V99++60GDhxIxwwAFaBzRtQVFBRo4MCBatasGYUZAMJA54yo2rlzp+bPn69x48apQYMGvuMAQEKgc0bUOOc0cuRIde7cmcIMAJVA54yo2LZtm9555x1NmDBBNWrwGxAAKoNvTURFdna2zjvvPAozAFQBnTMi6scff9SLL76owYMH+44CAAmLtgYR45zTG2+8od/97ne+owBAQqNzRkSsXbtW2dnZuvvuu31HAYCER+eMatu7d68WLlyoO+64w3cUAEgKFGdUy/Lly3XnnXfq/PPPV7169XzHAYCkQHFGla1du1bbt2/X+PHjZWa+4wBA0oiLbc7Z2dl69NFH1ahRI0lSbm6uMjIyvGZC+ZYsWaKnn35aY8eOVa1acfExAoCkERed89SpU7Vs2bKD1zMyMtSnTx+PiVCeRYsWqVatWho3bhyFGQCiIG6+WdPT05WTk+M7BirwzTffaOrUqRo9ejQHGAGAKOHbFWGbM2eOatasqXvuuYfCDABRxDcswrJ27Vq99dZbSk9PZ/IXAERZ3KzWRvz68MMP1aBBAw0fPpzCDAAxQOeMcu3cuVNffvmlunbtSmEGgBihc0aZ3nzzTdWuXVu33Xab7ygAkFLonFGq/Px8bdq0Seecc47vKACQcuic8ROvvvqqiouL1bdvX99RACAlUZxxiO3bt+uII47Qeeed5zsKAKQsijMOevbZZ1WjRg2OzgYAnlGcISlw5K+TTz5ZnTt39h0FAFIeE8KgJ598UosWLaIwA0CcoHNOce+9954uvfRSNWnSxHcUAEAQnXMKmzJlivbv309hBoA4Q+ecoqZMmaI+ffpwykcAiEN0zilo2rRpOvrooynMABCnwirOZnaBmS01s2VmNqSU+/ub2WIz+9rM3jOzdpGPiupyzumBBx7Q+eefr6ysLN9xAABlqLA4m1lNSY9IulBSZ0m9zazktN4vJWU6506S9LKk+yIdFNU3e/Zs9ejRQ3Xr1vUdBQBQjnA651MkLXPOrXDO5Ut6XtIloQs45z5wzu0JXv1MUpvIxkR1FBcX66mnntLxxx+v7t27+44DAKhAOBsdW0taE3J9raTyvuGvl/RmaXeY2Y2SbpSkFi1aKCcnR5KUl5enoqKig9cROUVFRVq9erW6deumBQsW+I6TtHbt2sXnN0oY2+hifKOnOmMb0RlBZna1pExJZ5Z2v3MuW1K2JGVmZroD2z0bNWqkvLw8toNGWGFhoe644w7ddNNNWrlyJeMbRTk5OYxvlDC20cX4Rk91xjac1drrJLUNud4meNshzOwcSXdKutg5t79KaRAxBQUFWrZsma6//nq1a8f8PABIJOEU57mSOpjZMWZWR1IvSdNCFzCzrpIeU6Aw/xj5mKiM/Px8DRo0SLVr19Zxxx3nOw4AoJIqXK3tnCs0s5slvS2ppqSnnHOLzOxuSfOcc9MkTZB0hKSXzEySVjvnLo5ibpRh3759+uabbzRgwAC1bt3adxwAQBWEtc3ZOTdD0owSt40IuXxOhHOhCoqKijRo0CANHDiQwgwACYxDRCWJ3bt367PPPtO4ceNUv35933EAANXA4TuTxN13360uXbpQmAEgCdA5J7i8vDy98cYbuvfeexXc3g8ASHB0zgnuySef1IUXXkhhBoAkQuecoDZv3qwpU6bo9ttv9x0FABBhdM4JyDmnt956S7///e99RwEARAHFOcH88MMPuuOOO3T11VerQYMGvuMAAKKA4pxAdu/ercWLF2vEiBEVLwwASFgU5wSxatUq3XHHHTrrrLN02GGH+Y4DAIgiinMCWLt2rfLy8jRhwgTVqMFbBgDJjm/6OPftt99q0qRJOuGEE1SnTh3fcQAAMUBxjmOLFy+WJI0fP161a9f2nAYAECsU5zi1fPlyTZkyRT/72c9Uqxa7owNAKqE4x6EvvvhC+/fv19ixY1WzZk3fcQAAMUZxjjM//vijpk+fruOPP57JXwCQolhfGkc+/vhj1apVSyNHjvQdBQDgEa1ZnNi7d6/mzp2r7t27+44CAPCMzjkOvPPOO8rPz1e/fv18RwEAxAE6Z88KCgq0ceNG9ezZ03cUAECcoHP2aNq0adq1a5euvvpq31EAAHGE4uzJtm3bVL9+fV188cW+owAA4gzF2YPnn39e+fn56tu3r+8oAIA4RHGOsUWLFqlr16467rjjfEcBAMQpJoTF0JQpU7Ro0SIKMwCgXHTOMTJz5kxdcsklSktL8x0FABDn6Jxj4Pnnn9f+/fspzACAsNA5R9nkyZN11VVXccpHAEDY6Jyj6K233lKbNm0ozACASqFzjgLnnB544AH96U9/Uv369X3HAQAkGDrnCHPOae7cufrlL39JYQYAVAnFOYKKi4t111136eijj9b//M//+I4DAEhQFOcIKS4u1rfffqvf/OY3atmype84AIAERnGOgKKiIg0dOlS1atXSySef7DsOACDBMSGsmgoLC7V8+XL97ne/U3p6uu84AIAkQOdcDQUFBRo0aJDMTJ06dfIdBwCQJOicq2j//v1atGiRbr/9drVu3dp3HABAEqFzroLi4mINHjxYTZs2pTADACKOzrmS9uzZo1mzZmncuHE67LDDfMcBACQhOudKGjNmjH7+859TmAEAUUPnHKYdO3botdde0z333CMz8x0HAJDE6JzD9PTTT6tnz54UZgBA1NE5V2Dr1q164oknNGjQIN9RAAApgs65HMXFxXrnnXf0hz/8wXcUAEAKoTiXYcOGDRo8eLCuvPJKpaWl+Y4DAEghFOdS7Ny5U998841GjhzJNmYAQMxRnEtYvXq17rjjDvXo0YPzMQMAvKA4h1izZo3y8vJ0//33q1Yt5soBAPygOActX75ckyZNUqdOnVS3bl3fcQAAKYz2UNI333wjSRo/frxq167tOQ0AINWlfOe8evVqPf300+rQoQOFGQAQF1K6c87NzVWNGjU0btw41aiR8r9TAABxImUrUl5enl577TV16dKFwgwAiCsp2Tl/9tlnys/P16hRo3xHAQDgJ1KuZczPz9enn36q008/3XcUAABKlVKd8/vvv6+8vDz169fPdxQAAMqUMp1zQUGB1q9fr8suu8x3FAAAypUSnfMbb7yhTZs26brrrvMdBQCACiV9cd68ebPq16+vnj17+o4CAEBYkro4v/TSS9q5c6f+7//+z3cUAADClrTF+euvv1bXrl2Vnp7uOwoAAJWSlBPCnnvuOS1YsIDCDABISEnXOb/55pvq2bOnGjZs6DsKAABVklTF+ZVXXlGNGjUozACAhJY0xXny5Mnq3bs352IGACS8pNjm/P7776tly5YUZgBAUkjoztk5p4kTJ+qGG25QWlqa7zgAAEREwnbOzjl9/fXX6tatG4UZAJBUErI4O+c0evRoNW7cWGeccYbvOAAARFTCrdYuLi7WihUrdOGFF+roo4/2HQcAgIhLqM65uLhYw4YNU0FBgbp16+Y7DgAAUZEwnXNRUZGWL1+uq6++Wscff7zvOAAARE1CdM6FhYUaPHiwioqK1LlzZ99xAACIqrjvnAsKCvTVV1/p9ttv11FHHeU7DgAAURfXnbNzTkOGDFGTJk0ozACAlBG3nfO+ffv07rvvasyYMapXr57vOAAAxEzcds733XefunbtSmEGAKScsIqzmV1gZkvNbJmZDSnl/rpm9kLw/s/NrH1VA+3atUtPPvmkhg8frtatW1f1YQAASFgVFmczqynpEUkXSuosqbeZlZwyfb2kbc65dEmTJI2vaqBnnnlGF198scysqg8BAEBCC6dzPkXSMufcCudcvqTnJV1SYplLJP0zePllSWdbJatrYWGhxowZoz/96U9q3rx5Zf4UAICkEk5xbi1pTcj1tcHbSl3GOVcoabukppUJsmvXLt10002V+RMAAJJSTGdrm9mNkm6UpBYtWignJ0eS1KxZM6WlpSk3NzeWcVLKrl27Do43Io/xjR7GNroY3+ipztiGU5zXSWobcr1N8LbSlllrZrUkpUnaUvKBnHPZkrIlKTMz02VlZUmSsrKylJOTowPXEXmMb3QxvtHD2EYX4xs91RnbcFZrz5XUwcyOMbM6knpJmlZimWmSrg1e/q2k951zrkqJAABIcRV2zs65QjO7WdLbkmpKeso5t8jM7pY0zzk3TdKTkp4xs2WStipQwAEAQBWYrwbXzDZJ+j7kpmaSNnsJkxoY3+hifKOHsY0uxjd6So5tO+dcWLsjeSvOJZnZPOdcpu8cyYrxjS7GN3oY2+hifKOnOmMbt4fvBAAgVVGcAQCIM/FUnLN9B0hyjG90Mb7Rw9hGF+MbPVUe27jZ5gwAAALiqXMGAADyUJxjefrJVBTG+PY3s8Vm9rWZvWdm7XzkTEQVjW3IcpebmTMzZsBWQjjja2ZXBj+/i8xsaqwzJqowvheONrMPzOzL4HfDr33kTERm9pSZ/WhmC8u438zs4eDYf21mJ4f1wM65mP1T4CAmyyUdK6mOpK8kdS6xzJ8l/SN4uZekF2KZMZH/hTm+v5J0ePDynxjfyI1tcLkGkmZJ+kxSpu/cifIvzM9uB0lfSmocvH6k79yJ8C/Msc2W9Kfg5c6SVvnOnSj/JJ0h6WRJC8u4/9eS3pRkkk6V9Hk4jxvrzjkmp59MYRWOr3PuA+fcnuDVzxQ4VjoqFs5nV5JGK3A+832xDJcEwhnf30t6xDm3TZKccz/GOGOiCmdsnaSGwctpkn6IYb6E5pybpcCRMctyiaQpLuAzSY3M7KiKHjfWxTkmp59MYeGMb6jrFfhFh4pVOLbB1VVtnXNvxDJYkgjns9tRUkczm21mn5nZBTFLl9jCGduRkq42s7WSZkj6S2yipYTKfi9LivEpIxE/zOxqSZmSzvSdJRmYWQ1JEyVd5zlKMqulwKrtLAXW+MwysxOdc3k+QyWJ3pImO+ceMLNfKnCuhC7OuWLfwVJVrDvnypx+UuWdfhKlCmd8ZWbnSLpT0sXOuf0xypboKhrbBpK6SMoxs1UKbFuaxqSwsIXz2V0raZpzrsA5t1LStwoUa5QvnLG9XtKLkuSc+1RSPQWOC43qC+t7uaRYF2dOPxldFY6vmXWV9JgChZltduErd2ydc9udc82cc+2dc+0V2J5/sXNunp+4CSec74bXFeiaZWbNFFjNvSKGGRNVOGO7WtLZkmRmxytQnDfFNGXymiapb3DW9qmStjvn1lf0RzFdre04/WRUhTm+EyQdIeml4Dy71c65i72FThBhji2qKMzxfVvSeWa2WFKRpIHOOdaqVSDMsb1d0uNm1k+ByWHX0RSFx8yeU+BHY7PgNvu7JNWWJOfcPxTYhv9rScsk7ZH0u7Ael/EHACC+cIQwAADiDMUZAIA4Q3EGACDOUJwBAIgzFGcAAOIMxRkAgDhDcQYAIM5QnAEAiDP/H4CiE6RaDYBBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1832736b9d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnpElEQVR4nO3deXxU1f3/8dcnkwBVQdkUBRSwYrVswQiOCASiiKDgXgULiIrgV3Bp1Wqt8kOtS+1Pa78qgrhgqdTlV4pFS5UatToqi4iAqIAgUFFBQayyJDm/P+6dMAlZJslkZnLn/Xw8eMzMnTszJzfhnZPPOfdcc84hIiLBlZXqBoiISP1S0IuIBJyCXkQk4BT0IiIBp6AXEQm47FQ3oLxWrVq5Dh06pLoZIiINyuLFi7c451pX9FzaBX2HDh1YtGhRqpshItKgmNn6yp5T6UZEJOAU9CIiAaegFxEJuLSr0YtI8uzZs4eNGzeyc+fOVDdF4tSkSRPatWtHTk5O3K9R0ItksI0bN9K0aVM6dOiAmaW6OVIN5xxbt25l48aNdOzYMe7XqXQjksF27txJy5YtFfINhJnRsmXLGv8FFqygj0Tgzju9WxGJi0K+YanN9ys4pZt//hOGDoWSEmjcGBYsgHA41a0SEUm54PTo33wTioq8oN+9GwoLU90iEanG1q1b6dGjBz169KBNmza0bdu29PHu3burfO2iRYuYNGlSjT6vQ4cObNmypS5NbpCC06MfPBimTAEzaNQI8vNT3SIRqUbLli1ZunQpAJMnT+aAAw7gl7/8ZenzRUVFZGdXHFN5eXnk5eUlo5kNXnB69OEwHHssdOqkso1IfarnsbAxY8Ywfvx4evfuzfXXX8+7775LOBwmNzeXE088kY8++giAwsJCTj/9dMD7JTF27Fjy8/Pp1KkTDzzwQNyft27dOgYOHEi3bt0oKCjgs88+A+DZZ5+lS5cudO/enX79+gGwYsUKevXqRY8ePejWrRuffPJJgr/6+hGcHj1Ajx7w1lsKeZHauPpq8HvXldq+HZYt80qkWVnQrRsceGDl+/foAfffX+OmbNy4kbfeeotQKMS3337LG2+8QXZ2Nq+88go33XQTzz///D6vWbVqFa+++io7duzg6KOPZsKECXHNNZ84cSKjR49m9OjRPPbYY0yaNIk5c+YwZcoU5s+fT9u2bdm2bRsAU6dO5aqrrmLkyJHs3r2b4uLiGn9tqRCcHj3Aj38Mn33m1ehFJPG2b/dCHrzb7dvr5WPOO+88QqGQ/5HbOe+88+jSpQvXXHMNK1asqPA1Q4cOpXHjxrRq1YqDDz6YL774Iq7PikQijBgxAoCf//zn/Pvf/wagT58+jBkzhunTp5cGejgc5re//S13330369ev50c/+lFdv9SkCFaP/sgjvR++deugc+dUt0akYYmn5x2JQEGB15lq1AhmzaqXv6D333//0vu/+c1vGDBgAH/9619Zt24d+ZWMvzVu3Lj0figUoqioqE5tmDp1Ku+88w7z5s3juOOOY/HixYwYMYLevXszb948hgwZwiOPPMLAgQPr9DnJEKwe/ZFHerdr1qS2HSJBFQ57Y2C33Za0sbDt27fTtm1bAJ544omEv/+JJ57I7NmzAZg1axZ9+/YFYM2aNfTu3ZspU6bQunVrNmzYwNq1a+nUqROTJk1i+PDhLFu2LOHtqQ/B69GDgl6kPoXDSR0Hu/766xk9ejS33347Q4cOrfP7devWjawsr497/vnn88c//pGLL76Y3/3ud7Ru3ZrHH38cgOuuu45PPvkE5xwFBQV0796du+++m6eeeoqcnBzatGnDTTfdVOf2JIM551LdhjLy8vJcrS884hw0bQqXXlqrASCRTPPhhx9yzDHHpLoZUkMVfd/MbLFzrsL5psEq3ZhBmzYwf76WQRAR8QUr6CMRbyB21SpvwEhhLyISsKAvLNw79UvLIIiIAEEL+vx8iJ4unZOjZRBERAha0IfD8Ic/ePd/+1udISsiQtCCHuCcc7zbrOB9aSIitRGoNIxE4M5HWxM54BTwFz4SkfQ1YMAA5s+fX2bb/fffz4QJEyp9TX5+PtEp2EOGDCldhybW5MmTuffee6v87Dlz5rBy5crSx7fccguvvPJKDVpfsdjF1tJFYIJ+3jzo2xdu/o1R8P1cIu+GUt0kEanGhRdeWHpWatTs2bO58MIL43r9iy++yEEHHVSrzy4f9FOmTOHkk0+u1Xulu8AE/aJFUFzsX3fE5VD4yWGpbpJIICVyleJzzz2XefPmlV5kZN26dfznP/+hb9++TJgwgby8PH76059y6623Vvj62AuJ3HHHHXTu3JmTTjqpdCljgOnTp3P88cfTvXt3zjnnHL7//nveeust5s6dy3XXXUePHj1Ys2YNY8aM4bnnngNgwYIF5Obm0rVrV8aOHcuuXbtKP+/WW2+lZ8+edO3alVWrVsX9tT799NN07dqVLl26cMMNNwBQXFzMmDFj6NKlC127duW+++4D4IEHHuDYY4+lW7duXHDBBTU8qvsKzBIIgwbB//k/3v1G2SXkfzsXdlzpnSkrItVKxSrFLVq0oFevXrz00ksMHz6c2bNnc/7552Nm3HHHHbRo0YLi4mIKCgpYtmwZ3bp1q/B9Fi9ezOzZs1m6dClFRUX07NmT4447DoCzzz6byy67DICbb76ZGTNmMHHiRIYNG8bpp5/OueeeW+a9du7cyZgxY1iwYAGdO3dm1KhRPPzww1x99dUAtGrViiVLlvDQQw9x77338uijj1Z90ID//Oc/3HDDDSxevJjmzZszaNAg5syZQ/v27dm0aRPLly8HKC1D3XXXXXz66ac0bty4wtJUTQWmRx8OQ69ecOihsGDyvwnzNtx4o06aEkmg+lilOLZ8E1u2eeaZZ+jZsye5ubmsWLGiTJmlvDfeeIOzzjqL/fbbj2bNmjFs2LDS55YvX07fvn3p2rUrs2bNqnSZ46iPPvqIjh070tlfAXf06NG8/vrrpc+fffbZABx33HGsW7curq9x4cKF5Ofn07p1a7Kzsxk5ciSvv/46nTp1Yu3atUycOJF//OMfNGvWDPDW4xk5ciR/+tOfKr3CVk0EpkcPXth/8AH0brfJ2/Dww/DYY7rilEgcUrVK8fDhw7nmmmtYsmQJ33//Pccddxyffvop9957LwsXLqR58+aMGTOGnTt31ur9x4wZw5w5c+jevTtPPPEEhXU8kTK6HHIilkJu3rw577//PvPnz2fq1Kk888wzPPbYY8ybN4/XX3+dF154gTvuuIMPPvigToEfmB49wNFHw/ffw6ZlW70NulC4SELVxyrFBxxwAAMGDGDs2LGlvflvv/2W/fffnwMPPJAvvviCl156qcr36NevH3PmzOGHH35gx44dvPDCC6XP7dixg0MPPZQ9e/Ywa9as0u1NmzZlx44d+7zX0Ucfzbp161i9ejUATz31FP3796/T19irVy9ee+01tmzZQnFxMU8//TT9+/dny5YtlJSUcM4553D77bezZMkSSkpK2LBhAwMGDODuu+9m+/btfPfdd3X6/ED16H/yE+92VftTaG/mrWapC4WLJFR9rFJ84YUXctZZZ5WWcLp3705ubi4/+clPaN++PX369Kny9T179uRnP/sZ3bt35+CDD+b4448vfe62226jd+/etG7dmt69e5eG+wUXXMBll13GAw88UDoIC9CkSRMef/xxzjvvPIqKijj++OMZP358jb6eBQsW0K5du9LHzz77LHfddRcDBgzAOcfQoUMZPnw477//PhdffDElfj3szjvvpLi4mIsuuojt27fjnGPSpEm1nlkUFahlijdv9mr0DzwAE5/rDx9+CH/7m8o2IpXQMsUNU0YvU3zIId4MgFWr8CbVf/019OyZ6maJiKRUoILeDNq29Zejz+nnTaz/+ONUN0tEJKUCFfSRiLfywZo1UHDnyUQ4AaqZSiWS6dKtfCtVq833K1BBX2Y5+iKj0AYq6EWq0KRJE7Zu3aqwbyCcc2zdupUmTZrU6HWBmnWTn+8tQ797N2RnG/mHrIEVu1PdLJG01a5dOzZu3MhXX32V6qZInJo0aVJmRk88AhX04TDMng1nnw2TJkH43c3wxgqvpqOZNyL7yMnJoWPHjqluhtSzQJVuAM4801ve5vu1m+HNN2HLFl0/VkQyWuCC3gy6dIHlS3bp+rEiIgQw6MEP+q8Pw+U08jZkZensWBHJWHEFvZkNNrOPzGy1mf2qgufvM7Ol/r+PzWxbzHOjzewT/9/oBLa9Ul26wNbtOXzxzGveEgjDhqlGLyIZq9rBWDMLAQ8CpwAbgYVmNtc5V7pmqHPumpj9JwK5/v0WwK1AHuCAxf5rv0noV1FOly7e7a//1otLjx5D+IvKlzcVEQm6eHr0vYDVzrm1zrndwGxgeBX7Xwg87d8/FXjZOfe1H+4vA4Pr0uB4/PCDd/v441Dw4R+JLGm8t14vIpJh4gn6tsCGmMcb/W37MLMjgI7Av2r62kRatsy7dQ52l2RT+P3xEOcFAkREgibRg7EXAM8554pr8iIzG2dmi8xsUSJO3MjP98ZfARrlOPIphFtu0RRLEclI8QT9JqB9zON2/raKXMDesk3cr3XOTXPO5Tnn8lq3bh1Hk6oWDsNFF3lTLV+8c5l3WcE//1nz6UUkI8UT9AuBo8yso5k1wgvzueV3MrOfAM2B2CSdDwwys+Zm1hwY5G+rd2ec4ZVuDli91NvgnObTi0hGqjbonXNFwJV4Af0h8IxzboWZTTGzYTG7XgDMdjGrIznnvgZuw/tlsRCY4m+rd7m53u17TftBKOQ90NWmRCQDBeoKU7FKSqB5cxg5Eh7a75fw+9/D8897C+GIiARMxlxhKlZWFnTqBH//O0SOGett1BRLEclAgQ36SASWL4cNG6Bg4jFEQifBwoWpbpaISNIFNujLXIRkt1HY4ix47jnNuhGRjBPYoM/P98ZeAbKshPyv/wpr12qKpYhknMAGfTgMCxZAkyYw+MerCZe86T2hKZYikmECG/QAJ54I/fvD+qK20Lixt1FLFotIhgl00AP06gXL1+7Pf//+Kuy3H5x6qpYsFpGMkhFBX1IC1/zlBCK5V8Dq1alukohIUgU+6M2820cfhYJ3f0tk1UGwdWtK2yQikkyBD/oySxYXhygkH669VjNvRCRjBD7o8/NjlrqJLln81FOaZikiGSPwQR8Ow3XXefcfO/MFb8lirWQpIhkk8EEPMNq/JPl/O3WFbP8yuVrJUkQyREYE/dFHw4EHwkPzjyRyxVPexrvu0jRLEckIGRH0b78NO3bAkiVQMP1nRLL6wJdfprpZIiJJkRFBX1joleXBX+Cs1bnegKwGY0UkA2RE0McucBayEvK3Pg+ffaaZNyKSETIi6KMLnO23HxR0WkvYveU9sWuXZt6ISOBlRNAD9OkDQ4bA8u3tcY20wJmIZI6MCXqAgQNhwxeN+eWZq4m0PRfatdPMGxEJvIwK+hYtvNv7/nIYBV/+mci6NrBxY2obJSJSzzIq6Nes8W6dg90l2d66N1dfrQFZEQm0jAr6AQNi1r3JLvHWvXn+ec2+EZFAy6igD4fhjju8+/ec8gphe8d7oHVvRCTAMiroAf7nfyAnB9Y36+rdAW/9G82+EZGAyrigP+AA6N4dZr5yGJF73/RCfvhwzb4RkcDKuKCPROD9972lbgZen0fkmIvh5ZfhrbdS3TQRkXqRcUFfWAjFxd79XbschSsOhm++0YCsiARWxgV9fj409k+MNfwrToGWQxCRwMq4oI+ue1NQACXOeCFrGBFO8J7UgKyIBFDGBT14Ye9ddcq4q/g6CrIKibje8MwzKt+ISOBkZNADbNjg3Tpn7CbHO0v2D39QrV5EAidjg37AgL2Xj83JKvZq9bpouIgEUMYGfTgMTz7p3R9/9leEcxZ7D3TylIgETMYGPcCIEfDjH8PzkcOI3P26txCOTp4SkYDJ6KCPRGD9eq9eP/CmE4h0uxzmzYM33kh100REEiajg76wEEpKvPu7djkKlzWH//4XTj5ZA7IiEhgZHfSxFw3HQd+S17z7GpAVkQDJ6KCPnjw1ciQ4jEezxhHBr8+vXKlevYgEQkYHPXhhP26cd//J4osoCL3qnSk7a5bm1ItIIMQV9GY22Mw+MrPVZvarSvY538xWmtkKM/tzzPZiM1vq/5ubqIYn0ptvghmAsbvEP3lKc+pFJCCyq9vBzELAg8ApwEZgoZnNdc6tjNnnKOBGoI9z7hszOzjmLX5wzvVIbLMTK7rQ2c6d4ICWoW1QjDfdUnPqRaSBi6dH3wtY7Zxb65zbDcwGhpfb5zLgQefcNwDOuS8T28z6FQ57qx+YQYnL4urs/yXSdBC0a+f16FW+EZEGLJ6gbwtsiHm80d8WqzPQ2czeNLO3zWxwzHNNzGyRv/3Mij7AzMb5+yz66quvatL+hNm6NVq+gV17QhR2nQhr18LNN6tWLyINWqIGY7OBo4B84EJgupkd5D93hHMuDxgB3G9mR5Z/sXNumnMuzzmX17p16wQ1qWZi16l3Dvp23uw9KClRrV5EGrR4gn4T0D7mcTt/W6yNwFzn3B7n3KfAx3jBj3Nuk3+7FigEcuvY5noRnWo5YoQX9A9vGk4kdJL3pBm0bJnaBoqI1FI8Qb8QOMrMOppZI+ACoPzsmTl4vXnMrBVeKWetmTU3s8Yx2/sAK0lT4TBMmODl+p9fbk1B1r+8qZZFRXD11SrfiEiDVG3QO+eKgCuB+cCHwDPOuRVmNsXMhvm7zQe2mtlK4FXgOufcVuAYYJGZve9vvyt2tk46euONmFp9UYhCBngPVL4RkQaq2umVAM65F4EXy227Jea+A671/8Xu8xbQte7NTJ5orf6HH7xLDa7P6kCk5ATC7l347DOvV6/VLUWkAcn4M2PLi72mLBjT3WUU2KtESnrBtGmagSMiDY6CvgLhMAwc6N0vccZO14iZjNIMHBFpkBT0lRgwAHJyvPsO43Eu9gZmQTNwRKRBUdBXIhyGSy6JPjKKrJG3Bk5xsWbgiEiDoqCvwqhR0KSJd7/EwXqO8Hr1P/wAkycr7EWkQVDQVyEchn/9C/r0AUcW07mMAhZ4Yf/KKxqYFZEGQUFfjXAYTjvNu19CiJ001sCsiDQoCvo4DBy495KDjiwNzIpIg6Kgj0M4DGPHRh8Zu2nEZG4lUnw8XHWVyjciktYU9HEaNQp+9CPvvsN4hVO8ev3OHhqYFZG0pqCPU/SM2f79vcdl6vUvv6yBWRFJWwr6GgiH4c47ISfHALe3Xu96e9chnDkz1U0UEdmHgr6G9p5IZYCxixyvXu96w+OPq1cvImlHQV8LsfV6CPEyg7x6/a5cuOUWhb2IpBUFfS1E6/UnnwzREk5pvV4nUolImlHQ11I4DFOmQKNGe+v107mUCTxE5IfuqteLSNpQ0NdBdH69mVevLyabR7jcK+NM+8C7LqF69iKSYgr6OooufBa9/GBpGadkJEydqjKOiKScgr6OovX6yy+H7JBj3zJOD5VxRCSlFPQJEA7Dww/DpZdl4XXsjWJymMrl9KOQaY+UqIwjIimjoE+gUaOgyY/ML+M4IIsicrjC/S8TpnYjkn+jwl5Ekk5Bn0CxZZxQllfGKTNIu/tFIve8kepmikiGUdAnWLSM89DDWeSEHFACxAzSzmnq/SZQz15EkkRBX0/GjYPX3shi/Pgssq0Yb5A2xCNcxiXTjifS93qYNi3VzRSRDKCgr0elg7TDt2A4ABwhHuMS+hb/i2njF2uQVkTqnYI+CUZd34YmjR3ml3Gis3Iudw8xZmovIv1uUOCLSL1R0CdBOAwLXg1x+fgsQlkl4PfuIYsnGUPfogWcOXUQE/osI3LDnBS2VESCyJxz1e+VRHl5eW7RokWpbka9mTYNrryihKJi70pV+DPvo+Gfw24uOfZtRl3VgvC4rilrp4g0LGa22DmXV9Fz6tEnWXSQ9vLxWTTOiZZzvGmYYOyhEVNX9qXf5Ucz7aLXUtxaEQkCBX0KRAdpX33NC/yckDcrJ7akU0QOV8zqw4SfvuYtkCYiUksq3aSBSARm3vM5m5du5oV1XSgmG6+H731vsini2kHLOSg/l/x87xeFiEisqko3Cvo0M+2i17hyVpgiQjiyiA18wxEKwYMPZTFuXEqbKSJpRjX6BmTcn/rz2iMfcfkx/yZEEXvr997ZtUXFxhXjSzjrLM3IFJH4qEefxvb27rNwhPyt5Wbp5BiXXOItqKaSjkjmUummAYtM+4DCGWvY9u5H3Mc15Uo6UFrHDzmu/UUWBx2E6vgiGUhBHwTTphG54ilmFo9gBmPZQ6OYJ2Pq+GZeHf9BVMcXySAK+qCIRGDmTCLTPmBmyUg2cwgvcEa5WTrebVaWMXQotG2rso5IJlDQB820aXDllVBUxDR3CVfyYJV1/Oxs49JLITcXtm5VaUckiBT0QRSJQGEhbNtG5PdvUVjcl2005T5+UUEdfy8zVNoRCaA6B72ZDQb+AISAR51zd1Wwz/nAZLxu5PvOuRH+9tHAzf5utzvnnqzqsxT0teCXdJg+nUjx8cxkVCV1/CivtHPGGXDooSrtiARBnYLezELAx8ApwEZgIXChc25lzD5HAc8AA51z35jZwc65L82sBbAIyMP7BbAYOM45901ln6egr4OYkk7E9WYmo9jMIbzEEPaQTck+pR1Pdjacfjq0aaPQF2moqgr67Dhe3wtY7Zxb67/ZbGA4sDJmn8uAB6MB7pz70t9+KvCyc+5r/7UvA4OBp2vzhUg1xo2Drl2hsJDwtm2E77uqNPQLyWcbzSos7RQVwZw53ls8+qhCXyRo4gn6tsCGmMcbgd7l9ukMYGZv4pV3Jjvn/lHJa9uW/wAzGweMAzj88MPjbbtUJBzem85nngkzZxJ+/HHCe96FkhLOZG6VpZ3Y0J8xA4YOVeiLNHTxBH2873MUkA+0A143s7gXU3fOTQOmgVe6SVCbJBr6o0aVDtyG77uPcNE7jHIzS0s78xhaYejv2VM29HUGrkjDFE/QbwLaxzxu52+LtRF4xzm3B/jUzD7GC/5NeOEf+9rC2jZWaqmiXv6MGYT3vA1AhBPiCv2pU2H6dPjFL9AZuCINSDyDsdl4g7EFeMG9EBjhnFsRs89gvAHa0WbWCngP6MHeAdie/q5L8AZjv67s8zQYmyTRmTqbN8MLL0Bxsbc5jtCPCoUU+iLpok6Dsc65IjO7EpiPV39/zDm3wsymAIucc3P95waZ2UqgGLjOObfV//Db8H45AEypKuQliWJ7+TGzdcLubcLs29Ov6Azc4mK45x7vLRT6IulLJ0yJJ+YELO67zxuVjfnZmMallZyBu3cZ5aicHBgyRHP0RZJJZ8ZKzUTLOjNmeMX56GZOKDdNs6JlF8oKhbzpmgp9kfqloJfaia3jz5sXV+gbDudf6Lw8hb5I/VHQS93FEfot2cJ79Kxm+QWPQl8ksRT0kliVzNgpfboGM3dAoS+SCAp6qT8xM3ZwzlseM+ZnqjahP2SI1tEXqSkFvdSv6Iydli3hvff2GcQt3a3S0K98IHfwYGjfXqEvUh0FvSRXFfX80l1KQ78N87LOYE9J9bN3Bg2CI47QBVREKqKgl9SpUegfyrys06sNfYCsLG955SFDtOiaCCjoJV1UM4gLtQt98E7S0kqbkskU9JJ+yg/iVkChLxI/Bb2kp2qWXSizqx/6WBa5p7TkvW2dmLG4B3uKs6r8CF09SzKFgl7SXw1CHwAzIqGTmNnuRm9Ad0P3akNf8/UlyBT00rDUNPTBC/32N9Uo9E87Ddq10yweCQYFvTRclYV+uROzyrykhqEP3tuFQnDttVpqWRomBb0EQ5wnZpV5SegkZra7ic0Wf+iDV9tX6EtDoqCXYIpjjn6Z3bP6MLP9r2sU+mZ719fXgK6kMwW9BF+tQv8m2H9/muUeyX3PtItnKIBQyJu6edhhqu1LelHQS2apYegTChHJm0ih68+2o/LKhH4VQwGAavuSPhT0krlqGvpZWUS6j6cw52RaHtWC9z5pGtd8/SjV9iVVFPQiUPPQh1rN14+KXjD922+9x6rvS31S0IuUV5vQZ+/UTfbbr0a1fdBZulK/FPQiVall6JOdTeTEX1C484R9avvVib3AigZ1JREU9CLxioY+eAkc53x9QiEv9HeFaxz6oGmcUncKepG6qM0snhOupnDPSbQ8qjnvfdKUzU2OYF6kZU3+WGDoUG9dHvX4JR4KepFEqeWALqEQkZ/dz8xPwjUO/Zi30IweqZSCXqQ+1KW274c+hx1G7mlt4q4QxbwF116rGT2yl4JepL7VIfSj3fRIy9OZ+V7XGr8F6GIroqAXSa7YAd1mzeJeapmcHG/t5MMOI9LsVGYWHg6HHUazzm3ifgvQEsyZSkEvkkq1WF8fKFOYj3z7Uwrpz7ZmR9ToLaJ0xm7wKehF0kUt1tcv5ad1NPRb5h7Be+/Vrlo0eLB6/EGjoBdJR7VYX79UKASTJsEPP3hvlXtFrev7oMHdIFDQizQEta3tQ5kL4kZDv6K3iecPByi7XIN6/Q2Dgl6kIaptbT8UgoED4cgjITeXyHtNypR6avKHQ5Tm8ac/Bb1IQ1fb0I+qYBon1PwPh6hQCK65Br77znusUk/qKehFgqR8bb+mhfmYaZwV9fhrU+fXlM7UU9CLBF1tT9iCCusyEcK1Hi6IvmXsIm0K//qnoBfJJFUN6tZgGmfsFJwI4TpVjqp4awV/gijoRTJZXaZxQtmlNGNCv6rKkWb3JJ+CXkT2qus0zn79oHNn6NmzNJljSz01Wca/vNgqknr9NVPnoDezwcAfgBDwqHPurnLPjwF+B2zyN/2vc+5R/7li4AN/+2fOuWFVfZaCXiTJ6jqjp5IpOHX5fRIrdsE29forV6egN7MQ8DFwCrARWAhc6JxbGbPPGCDPOXdlBa//zjl3QLyNVdCLpFBdZ/SAF/xjx0JeXplUTsRbgwZ6K1PXoA8Dk51zp/qPbwRwzt0Zs88YFPQiwVSXGT2wz3INsbWYRPX6VfKpe9CfCwx2zl3qP/450Ds21P2gvxP4Cq/3f41zboP/XBGwFCgC7nLOzangM8YB4wAOP/zw49avX1+zr1BEkiMRyRwKeauqtW+/T3c8Ub1+yLzLMSYj6FsC3znndpnZ5cDPnHMD/efaOuc2mVkn4F9AgXNuTWWfpx69SANSUTK/9JKXzCUl8b9PFfMua3u99hp+TINX76WbcvuHgK+dcwdW8NwTwN+dc89V9nkKepEGrq6Du1B23mUFaZyokk+Qzuita9Bn45VjCvBm1SwERjjnVsTsc6hz7nP//lnADc65E8ysOfC939NvBUSA4bEDueUp6EUCJFGDuwUF0KlTpWmcyJJPKARXXgmHHLL3/SD9e/+JmF45BLgfb3rlY865O8xsCrDIOTfXzO4EhuHV4b8GJjjnVpnZicAjQAmQBdzvnJtR1Wcp6EUCrq7dcTOvxz9kSJUF+ET1+qPSfZqnTpgSkfSVqO54NQX4RPb64/zIpFLQi0jDUtWUzpqsr1DNtJu6LgtUXigEp5wCRxzhnTiczLKPgl5EGq4kTruJ7fVv3Zq43n8ypnoq6EUkWBI57Wbo0NK1+atK4ETX/KPnkbVunZhBXwW9iARbos+0iq7NH+3aVxD+9VHzB2jcGF59teZhX1XQZ9etSSIiaSAc3jcZa9sFLyqCe+4pu62Ckk84HK7yI6NVppr+Ati92/sFktCyjnr0IpIREt3rHzIkrpJP9KPjHfStjx69gl5EMlcip91kZ3vLNe/Y4T2uothe2aBvNS+rkoJeRCQe5RO4Lss4hEIwYAAceWRS5loq6EVEaivRo671NNdSg7EiIrWVyIFe8Pb729/2Po5eSeW000qvy5voHr969CIidZXIXn8tR2PVoxcRqU/V9fqrmmtZftC3HuZXKuhFROpDReEP1S/p0KiRV7NPIAW9iEgyVfQLYNSoveFfDzV6Bb2ISKpV1vtPkKx6e2cREUkLCnoRkYBT0IuIBJyCXkQk4BT0IiIBp6AXEQm4tFsCwcy+AtbX4S1aAVsS1JxEUrtqJl3bBenbNrWrZtK1XVC7th3hnGtd0RNpF/R1ZWaLKlvvIZXUrppJ13ZB+rZN7aqZdG0XJL5tKt2IiAScgl5EJOCCGPTTUt2ASqhdNZOu7YL0bZvaVTPp2i5IcNsCV6MXEZGygtijFxGRGAp6EZGAC0zQm9lgM/vIzFab2a9S2I72Zvaqma00sxVmdpW/fbKZbTKzpf6/ISlq3zoz+8BvwyJ/Wwsze9nMPvFvmye5TUfHHJelZvatmV2dimNmZo+Z2ZdmtjxmW4XHxzwP+D9zy8ysZ5Lb9TszW+V/9l/N7CB/ewcz+yHmuE2tr3ZV0bZKv3dmdqN/zD4ys1OT3K6/xLRpnZkt9bcn7ZhVkRH193PmnGvw/4AQsAboBDQC3geOTVFbDgV6+vebAh8DxwKTgV+mwbFaB7Qqt+0e4Ff+/V8Bd6f4e7kZOCIVxwzoB/QElld3fIAhwEuAAScA7yS5XYOAbP/+3THt6hC7X4qOWYXfO///wvtAY6Cj//82lKx2lXv+98AtyT5mVWREvf2cBaVH3wtY7Zxb65zbDcwGhqeiIc65z51zS/z7O4APgbapaEsNDAee9O8/CZyZuqZQAKxxztXl7Ohac869DnxdbnNlx2c4MNN53gYOMrNDk9Uu59w/nXNF/sO3gXb18dnVqeSYVWY4MNs5t8s59ymwGu//b1LbZWYGnA88XR+fXZUqMqLefs6CEvRtgQ0xjzeSBuFqZh2AXOAdf9OV/p9ejyW7PBLDAf80s8VmNs7fdohz7nP//mbgkNQ0DYALKPufLx2OWWXHJ51+7sbi9fqiOprZe2b2mpn1TVGbKvrepcsx6wt84Zz7JGZb0o9ZuYyot5+zoAR92jGzA4Dngaudc98CDwNHAj2Az/H+bEyFk5xzPYHTgP8xs36xTzrvb8WUzLk1s0bAMOBZf1O6HLNSqTw+lTGzXwNFwCx/0+fA4c65XOBa4M9m1izJzUq77105F1K2Q5H0Y1ZBRpRK9M9ZUIJ+E9A+5nE7f1tKmFkO3jdwlnPu/wE4575wzhU750qA6dTTn6vVcc5t8m+/BP7qt+OL6J+C/u2XqWgb3i+fJc65L/w2psUxo/Ljk/KfOzMbA5wOjPTDAb8sstW/vxivDt45me2q4nuXDscsGzgb+Et0W7KPWUUZQT3+nAUl6BcCR5lZR79XeAEwNxUN8Wt/M4APnXP/N2Z7bE3tLGB5+dcmoW37m1nT6H28wbzleMdqtL/baOBvyW6br0wvKx2Oma+y4zMXGOXPijgB2B7zp3e9M7PBwPXAMOfc9zHbW5tZyL/fCTgKWJusdvmfW9n3bi5wgZk1NrOOftveTWbbgJOBVc65jdENyTxmlWUE9flzloxR5mT8wxuZ/hjvN/GvU9iOk/D+5FoGLPX/DQGeAj7wt88FDk1B2zrhzXh4H1gRPU5AS2AB8AnwCtAiBW3bH9gKHBizLenHDO8XzefAHrxa6CWVHR+8WRAP+j9zHwB5SW7XarzabfTnbKq/7zn+93cpsAQ4IwXHrNLvHfBr/5h9BJyWzHb5258AxpfbN2nHrIqMqLefMy2BICIScEEp3YiISCUU9CIiAaegFxEJOAW9iEjAKehFRAJOQS8iEnAKehGRgPv/XjoKMWUuE7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7240 - val_loss: 0.5393 - val_accuracy: 0.7448\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5322 - accuracy: 0.7240 - val_loss: 0.5390 - val_accuracy: 0.7448\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5319 - accuracy: 0.7240 - val_loss: 0.5387 - val_accuracy: 0.7448\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7240 - val_loss: 0.5384 - val_accuracy: 0.7448\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.7240 - val_loss: 0.5382 - val_accuracy: 0.7448\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7240 - val_loss: 0.5379 - val_accuracy: 0.7448\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5307 - accuracy: 0.7240 - val_loss: 0.5376 - val_accuracy: 0.7448\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5303 - accuracy: 0.7240 - val_loss: 0.5373 - val_accuracy: 0.7448\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5301 - accuracy: 0.7240 - val_loss: 0.5370 - val_accuracy: 0.7448\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.7240 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7240 - val_loss: 0.5365 - val_accuracy: 0.7500\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5292 - accuracy: 0.7240 - val_loss: 0.5362 - val_accuracy: 0.7500\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5289 - accuracy: 0.7257 - val_loss: 0.5359 - val_accuracy: 0.7500\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5285 - accuracy: 0.7274 - val_loss: 0.5357 - val_accuracy: 0.7500\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5283 - accuracy: 0.7292 - val_loss: 0.5354 - val_accuracy: 0.7448\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5280 - accuracy: 0.7292 - val_loss: 0.5351 - val_accuracy: 0.7448\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7292 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5274 - accuracy: 0.7292 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5271 - accuracy: 0.7292 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5268 - accuracy: 0.7309 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.5265 - accuracy: 0.7309 - val_loss: 0.5338 - val_accuracy: 0.7448\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5262 - accuracy: 0.7309 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7309 - val_loss: 0.5333 - val_accuracy: 0.7448\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.7309 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7326 - val_loss: 0.5327 - val_accuracy: 0.7448\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5251 - accuracy: 0.7344 - val_loss: 0.5325 - val_accuracy: 0.7448\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 0.5248 - accuracy: 0.7326 - val_loss: 0.5322 - val_accuracy: 0.7448\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7326 - val_loss: 0.5320 - val_accuracy: 0.7448\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.7326 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5240 - accuracy: 0.7326 - val_loss: 0.5315 - val_accuracy: 0.7448\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7344 - val_loss: 0.5312 - val_accuracy: 0.7500\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5234 - accuracy: 0.7326 - val_loss: 0.5310 - val_accuracy: 0.7500\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.7326 - val_loss: 0.5307 - val_accuracy: 0.7500\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.7344 - val_loss: 0.5305 - val_accuracy: 0.7500\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5226 - accuracy: 0.7344 - val_loss: 0.5302 - val_accuracy: 0.7500\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5223 - accuracy: 0.7326 - val_loss: 0.5300 - val_accuracy: 0.7500\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7344 - val_loss: 0.5297 - val_accuracy: 0.7500\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7378 - val_loss: 0.5295 - val_accuracy: 0.7500\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5215 - accuracy: 0.7396 - val_loss: 0.5292 - val_accuracy: 0.7500\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5213 - accuracy: 0.7396 - val_loss: 0.5290 - val_accuracy: 0.7500\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7396 - val_loss: 0.5287 - val_accuracy: 0.7500\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7396 - val_loss: 0.5285 - val_accuracy: 0.7500\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.7396 - val_loss: 0.5283 - val_accuracy: 0.7500\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5202 - accuracy: 0.7396 - val_loss: 0.5280 - val_accuracy: 0.7500\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5199 - accuracy: 0.7396 - val_loss: 0.5278 - val_accuracy: 0.7552\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.7396 - val_loss: 0.5276 - val_accuracy: 0.7552\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.7378 - val_loss: 0.5273 - val_accuracy: 0.7552\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7378 - val_loss: 0.5271 - val_accuracy: 0.7552\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7378 - val_loss: 0.5269 - val_accuracy: 0.7552\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7378 - val_loss: 0.5266 - val_accuracy: 0.7552\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7378 - val_loss: 0.5264 - val_accuracy: 0.7552\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5181 - accuracy: 0.7378 - val_loss: 0.5262 - val_accuracy: 0.7552\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.7378 - val_loss: 0.5259 - val_accuracy: 0.7552\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7378 - val_loss: 0.5257 - val_accuracy: 0.7552\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7378 - val_loss: 0.5255 - val_accuracy: 0.7552\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.7378 - val_loss: 0.5253 - val_accuracy: 0.7552\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7378 - val_loss: 0.5250 - val_accuracy: 0.7552\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.7378 - val_loss: 0.5248 - val_accuracy: 0.7552\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7378 - val_loss: 0.5246 - val_accuracy: 0.7552\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5162 - accuracy: 0.7378 - val_loss: 0.5244 - val_accuracy: 0.7552\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5159 - accuracy: 0.7378 - val_loss: 0.5241 - val_accuracy: 0.7552\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7396 - val_loss: 0.5239 - val_accuracy: 0.7552\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5154 - accuracy: 0.7378 - val_loss: 0.5237 - val_accuracy: 0.7500\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5152 - accuracy: 0.7396 - val_loss: 0.5235 - val_accuracy: 0.7500\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5150 - accuracy: 0.7396 - val_loss: 0.5233 - val_accuracy: 0.7500\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5147 - accuracy: 0.7396 - val_loss: 0.5231 - val_accuracy: 0.7500\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.7396 - val_loss: 0.5229 - val_accuracy: 0.7500\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5142 - accuracy: 0.7396 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5140 - accuracy: 0.7396 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.7413 - val_loss: 0.5222 - val_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5135 - accuracy: 0.7413 - val_loss: 0.5220 - val_accuracy: 0.7448\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7413 - val_loss: 0.5218 - val_accuracy: 0.7448\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7413 - val_loss: 0.5216 - val_accuracy: 0.7448\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5128 - accuracy: 0.7413 - val_loss: 0.5214 - val_accuracy: 0.7448\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.7413 - val_loss: 0.5212 - val_accuracy: 0.7448\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.7413 - val_loss: 0.5210 - val_accuracy: 0.7448\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.7431 - val_loss: 0.5208 - val_accuracy: 0.7448\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7431 - val_loss: 0.5206 - val_accuracy: 0.7448\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5117 - accuracy: 0.7448 - val_loss: 0.5204 - val_accuracy: 0.7448\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5115 - accuracy: 0.7448 - val_loss: 0.5202 - val_accuracy: 0.7448\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.7448 - val_loss: 0.5200 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7448 - val_loss: 0.5198 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5108 - accuracy: 0.7448 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7448 - val_loss: 0.5194 - val_accuracy: 0.7448\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5103 - accuracy: 0.7448 - val_loss: 0.5192 - val_accuracy: 0.7500\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7448 - val_loss: 0.5190 - val_accuracy: 0.7500\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.7465 - val_loss: 0.5188 - val_accuracy: 0.7500\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5097 - accuracy: 0.7448 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7448 - val_loss: 0.5184 - val_accuracy: 0.7500\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5092 - accuracy: 0.7431 - val_loss: 0.5182 - val_accuracy: 0.7500\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5090 - accuracy: 0.7431 - val_loss: 0.5180 - val_accuracy: 0.7500\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5088 - accuracy: 0.7448 - val_loss: 0.5178 - val_accuracy: 0.7500\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7465 - val_loss: 0.5176 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.7483 - val_loss: 0.5174 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7465 - val_loss: 0.5172 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7483 - val_loss: 0.5171 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5077 - accuracy: 0.7483 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7483 - val_loss: 0.5167 - val_accuracy: 0.7500\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5073 - accuracy: 0.7500 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5071 - accuracy: 0.7517 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7535 - val_loss: 0.5161 - val_accuracy: 0.7500\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7535 - val_loss: 0.5160 - val_accuracy: 0.7552\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7517 - val_loss: 0.5158 - val_accuracy: 0.7552\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7535 - val_loss: 0.5156 - val_accuracy: 0.7656\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7517 - val_loss: 0.5154 - val_accuracy: 0.7656\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5059 - accuracy: 0.7535 - val_loss: 0.5152 - val_accuracy: 0.7656\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7535 - val_loss: 0.5151 - val_accuracy: 0.7656\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.7535 - val_loss: 0.5149 - val_accuracy: 0.7656\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5053 - accuracy: 0.7535 - val_loss: 0.5147 - val_accuracy: 0.7656\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.7517 - val_loss: 0.5145 - val_accuracy: 0.7656\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7552 - val_loss: 0.5144 - val_accuracy: 0.7656\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7535 - val_loss: 0.5142 - val_accuracy: 0.7656\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.7535 - val_loss: 0.5140 - val_accuracy: 0.7708\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5043 - accuracy: 0.7535 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7535 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5039 - accuracy: 0.7517 - val_loss: 0.5135 - val_accuracy: 0.7708\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7517 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5033 - accuracy: 0.7535 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5031 - accuracy: 0.7535 - val_loss: 0.5128 - val_accuracy: 0.7708\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5030 - accuracy: 0.7535 - val_loss: 0.5127 - val_accuracy: 0.7708\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.7535 - val_loss: 0.5125 - val_accuracy: 0.7708\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7535 - val_loss: 0.5123 - val_accuracy: 0.7708\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7535 - val_loss: 0.5122 - val_accuracy: 0.7708\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7535 - val_loss: 0.5120 - val_accuracy: 0.7708\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.7535 - val_loss: 0.5118 - val_accuracy: 0.7708\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7535 - val_loss: 0.5117 - val_accuracy: 0.7708\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5016 - accuracy: 0.7535 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7535 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.7535 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7535 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7517 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7535 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7535 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7552 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.7552 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.7535 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.7569 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7569 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7569 - val_loss: 0.5096 - val_accuracy: 0.7604\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7535 - val_loss: 0.5095 - val_accuracy: 0.7604\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7569 - val_loss: 0.5093 - val_accuracy: 0.7604\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7569 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.7569 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4986 - accuracy: 0.7569 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.7587 - val_loss: 0.5088 - val_accuracy: 0.7604\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4982 - accuracy: 0.7587 - val_loss: 0.5086 - val_accuracy: 0.7604\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4980 - accuracy: 0.7587 - val_loss: 0.5085 - val_accuracy: 0.7604\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4979 - accuracy: 0.7587 - val_loss: 0.5083 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4977 - accuracy: 0.7587 - val_loss: 0.5082 - val_accuracy: 0.7604\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4975 - accuracy: 0.7587 - val_loss: 0.5080 - val_accuracy: 0.7604\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7569 - val_loss: 0.5079 - val_accuracy: 0.7604\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7569 - val_loss: 0.5077 - val_accuracy: 0.7604\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4970 - accuracy: 0.7587 - val_loss: 0.5076 - val_accuracy: 0.7604\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7569 - val_loss: 0.5075 - val_accuracy: 0.7604\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7587 - val_loss: 0.5073 - val_accuracy: 0.7604\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.7587 - val_loss: 0.5072 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7587 - val_loss: 0.5070 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7587 - val_loss: 0.5069 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7587 - val_loss: 0.5068 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7569 - val_loss: 0.5066 - val_accuracy: 0.7656\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4957 - accuracy: 0.7587 - val_loss: 0.5065 - val_accuracy: 0.7656\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4955 - accuracy: 0.7569 - val_loss: 0.5064 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7569 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4952 - accuracy: 0.7569 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4951 - accuracy: 0.7569 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4949 - accuracy: 0.7569 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.7569 - val_loss: 0.5057 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4946 - accuracy: 0.7569 - val_loss: 0.5055 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4945 - accuracy: 0.7587 - val_loss: 0.5054 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4943 - accuracy: 0.7587 - val_loss: 0.5053 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4941 - accuracy: 0.7604 - val_loss: 0.5052 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7604 - val_loss: 0.5050 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7587 - val_loss: 0.5049 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4937 - accuracy: 0.7587 - val_loss: 0.5048 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4935 - accuracy: 0.7587 - val_loss: 0.5046 - val_accuracy: 0.7760\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7587 - val_loss: 0.5045 - val_accuracy: 0.7760\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.7587 - val_loss: 0.5044 - val_accuracy: 0.7760\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7760\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7604 - val_loss: 0.5041 - val_accuracy: 0.7708\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4927 - accuracy: 0.7604 - val_loss: 0.5040 - val_accuracy: 0.7708\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4926 - accuracy: 0.7604 - val_loss: 0.5039 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7604 - val_loss: 0.5038 - val_accuracy: 0.7708\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7604 - val_loss: 0.5036 - val_accuracy: 0.7708\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7604 - val_loss: 0.5035 - val_accuracy: 0.7708\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7604 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7604 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7604 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7587 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4914 - accuracy: 0.7587 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4913 - accuracy: 0.7569 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4911 - accuracy: 0.7587 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.7587 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4909 - accuracy: 0.7587 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7587 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.7587 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7587 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4901 - accuracy: 0.7604 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4900 - accuracy: 0.7604 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4899 - accuracy: 0.7604 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4897 - accuracy: 0.7639 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.7639 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.7639 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4893 - accuracy: 0.7639 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.7639 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7639 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4889 - accuracy: 0.7639 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.7639 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.7639 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4885 - accuracy: 0.7639 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7656 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7656 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4881 - accuracy: 0.7656 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4880 - accuracy: 0.7656 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7656 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.7656 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4876 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7656 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7656 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7656 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4871 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7656\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7656 - val_loss: 0.4993 - val_accuracy: 0.7656\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7656 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4867 - accuracy: 0.7656 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4866 - accuracy: 0.7656 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7656 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4863 - accuracy: 0.7656 - val_loss: 0.4988 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4862 - accuracy: 0.7656 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7656 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4859 - accuracy: 0.7656 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4858 - accuracy: 0.7656 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7656 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7656 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4855 - accuracy: 0.7656 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.7656 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7656 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7656 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4847 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4845 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7674 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7674 - val_loss: 0.4970 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4839 - accuracy: 0.7674 - val_loss: 0.4969 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.7691 - val_loss: 0.4968 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7708 - val_loss: 0.4967 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7708 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7708 - val_loss: 0.4965 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4832 - accuracy: 0.7708 - val_loss: 0.4964 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4831 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4830 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7708 - val_loss: 0.4961 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7708 - val_loss: 0.4960 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4827 - accuracy: 0.7708 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7708 - val_loss: 0.4959 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4820 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7656\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4812 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7656\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7656\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7708 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.7691 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.7691 - val_loss: 0.4943 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4801 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.7691 - val_loss: 0.4938 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7691 - val_loss: 0.4937 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7691 - val_loss: 0.4936 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7691 - val_loss: 0.4935 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7691 - val_loss: 0.4934 - val_accuracy: 0.7708\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7691 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4791 - accuracy: 0.7691 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7691 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7708 - val_loss: 0.4926 - val_accuracy: 0.7708\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7726 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.7726 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7726 - val_loss: 0.4922 - val_accuracy: 0.7708\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7726 - val_loss: 0.4921 - val_accuracy: 0.7708\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7726 - val_loss: 0.4920 - val_accuracy: 0.7708\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4772 - accuracy: 0.7726 - val_loss: 0.4919 - val_accuracy: 0.7708\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7708\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.7708 - val_loss: 0.4917 - val_accuracy: 0.7708\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.7726 - val_loss: 0.4916 - val_accuracy: 0.7708\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.7726 - val_loss: 0.4915 - val_accuracy: 0.7708\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7708\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7743 - val_loss: 0.4913 - val_accuracy: 0.7708\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7760 - val_loss: 0.4912 - val_accuracy: 0.7708\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7760\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7760\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7760\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7708\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7743 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7760 - val_loss: 0.4908 - val_accuracy: 0.7708\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7760 - val_loss: 0.4907 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.4906 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4905 - val_accuracy: 0.7708\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.4904 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.7726 - val_loss: 0.4902 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.4902 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7743 - val_loss: 0.4901 - val_accuracy: 0.7708\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7743 - val_loss: 0.4900 - val_accuracy: 0.7760\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4899 - val_accuracy: 0.7760\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.7726 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7726 - val_loss: 0.4898 - val_accuracy: 0.7760\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.7726 - val_loss: 0.4897 - val_accuracy: 0.7760\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.7743 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.4896 - val_accuracy: 0.7760\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.4895 - val_accuracy: 0.7760\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.7743 - val_loss: 0.4894 - val_accuracy: 0.7760\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.7760 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7760 - val_loss: 0.4893 - val_accuracy: 0.7760\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7743 - val_loss: 0.4892 - val_accuracy: 0.7760\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7743 - val_loss: 0.4891 - val_accuracy: 0.7760\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7743 - val_loss: 0.4890 - val_accuracy: 0.7760\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.7760 - val_loss: 0.4889 - val_accuracy: 0.7760\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7760 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4888 - val_accuracy: 0.7760\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.7743 - val_loss: 0.4887 - val_accuracy: 0.7760\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4886 - val_accuracy: 0.7760\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7743 - val_loss: 0.4885 - val_accuracy: 0.7760\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7778 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.7743 - val_loss: 0.4884 - val_accuracy: 0.7760\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7743 - val_loss: 0.4883 - val_accuracy: 0.7760\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.7743 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7760 - val_loss: 0.4882 - val_accuracy: 0.7760\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7760 - val_loss: 0.4881 - val_accuracy: 0.7760\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4718 - accuracy: 0.7743 - val_loss: 0.4881 - val_accuracy: 0.7760\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7743 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7760 - val_loss: 0.4880 - val_accuracy: 0.7760\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4879 - val_accuracy: 0.7760\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7760\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4878 - val_accuracy: 0.7760\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7760\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7760 - val_loss: 0.4877 - val_accuracy: 0.7760\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7760 - val_loss: 0.4876 - val_accuracy: 0.7760\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7760 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.7743 - val_loss: 0.4875 - val_accuracy: 0.7760\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7760 - val_loss: 0.4874 - val_accuracy: 0.7760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7743 - val_loss: 0.4874 - val_accuracy: 0.7760\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7760 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7743 - val_loss: 0.4873 - val_accuracy: 0.7760\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4705 - accuracy: 0.7760 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4704 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.4872 - val_accuracy: 0.7760\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7778 - val_loss: 0.4871 - val_accuracy: 0.7760\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4871 - val_accuracy: 0.7760\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.7743 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7743 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7743 - val_loss: 0.4870 - val_accuracy: 0.7760\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4869 - val_accuracy: 0.7760\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.7760 - val_loss: 0.4869 - val_accuracy: 0.7760\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7743 - val_loss: 0.4868 - val_accuracy: 0.7760\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7760 - val_loss: 0.4868 - val_accuracy: 0.7760\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7778 - val_loss: 0.4868 - val_accuracy: 0.7760\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7726 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7743 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.7726 - val_loss: 0.4867 - val_accuracy: 0.7760\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7726 - val_loss: 0.4866 - val_accuracy: 0.7760\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.7726 - val_loss: 0.4866 - val_accuracy: 0.7760\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4694 - accuracy: 0.7726 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7726 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7743 - val_loss: 0.4865 - val_accuracy: 0.7760\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7726 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.7726 - val_loss: 0.4864 - val_accuracy: 0.7760\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7726 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4863 - val_accuracy: 0.7760\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7708 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.4862 - val_accuracy: 0.7760\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7708 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.7726 - val_loss: 0.4861 - val_accuracy: 0.7760\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.7708 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7726 - val_loss: 0.4860 - val_accuracy: 0.7760\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7708 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4683 - accuracy: 0.7726 - val_loss: 0.4859 - val_accuracy: 0.7760\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7708 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7726 - val_loss: 0.4858 - val_accuracy: 0.7760\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7726 - val_loss: 0.4857 - val_accuracy: 0.7760\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7708 - val_loss: 0.4856 - val_accuracy: 0.7760\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7691 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7708 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.4855 - val_accuracy: 0.7708\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4854 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.7708 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.4854 - val_accuracy: 0.7708\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7708 - val_loss: 0.4853 - val_accuracy: 0.7708\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7708 - val_loss: 0.4853 - val_accuracy: 0.7708\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7708 - val_loss: 0.4853 - val_accuracy: 0.7708\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7691 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7708 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7708 - val_loss: 0.4852 - val_accuracy: 0.7708\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7708 - val_loss: 0.4851 - val_accuracy: 0.7708\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7708 - val_loss: 0.4851 - val_accuracy: 0.7656\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7691 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7708 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7691 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.7708 - val_loss: 0.4850 - val_accuracy: 0.7656\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.4849 - val_accuracy: 0.7656\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.7691 - val_loss: 0.4848 - val_accuracy: 0.7656\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7708 - val_loss: 0.4847 - val_accuracy: 0.7656\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.7691 - val_loss: 0.4846 - val_accuracy: 0.7656\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.4845 - val_accuracy: 0.7656\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7691 - val_loss: 0.4844 - val_accuracy: 0.7656\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4656 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7708 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7708 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7691 - val_loss: 0.4843 - val_accuracy: 0.7656\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4654 - accuracy: 0.7708 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4654 - accuracy: 0.7691 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.7708 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4653 - accuracy: 0.7708 - val_loss: 0.4842 - val_accuracy: 0.7656\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7708 - val_loss: 0.4841 - val_accuracy: 0.7656\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4650 - accuracy: 0.7708 - val_loss: 0.4840 - val_accuracy: 0.7656\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7708 - val_loss: 0.4840 - val_accuracy: 0.7656\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.7708 - val_loss: 0.4840 - val_accuracy: 0.7656\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.4840 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7708 - val_loss: 0.4839 - val_accuracy: 0.7656\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7691 - val_loss: 0.4839 - val_accuracy: 0.7656\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7708 - val_loss: 0.4839 - val_accuracy: 0.7656\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.4839 - val_accuracy: 0.7656\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.4839 - val_accuracy: 0.7656\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.4838 - val_accuracy: 0.7656\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4838 - val_accuracy: 0.7656\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.4838 - val_accuracy: 0.7656\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.4838 - val_accuracy: 0.7656\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.4838 - val_accuracy: 0.7656\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7691 - val_loss: 0.4837 - val_accuracy: 0.7656\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7708 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.4836 - val_accuracy: 0.7656\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7708 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7691 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4640 - accuracy: 0.7708 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7708 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7708 - val_loss: 0.4835 - val_accuracy: 0.7656\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7708 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.7708 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7708 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7691 - val_loss: 0.4834 - val_accuracy: 0.7656\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7691 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.7708 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7708 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4833 - val_accuracy: 0.7656\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.7708 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7691 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4832 - val_accuracy: 0.7656\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7708 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7691 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7691 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.4831 - val_accuracy: 0.7656\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7691 - val_loss: 0.4830 - val_accuracy: 0.7656\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7708 - val_loss: 0.4829 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7691 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7708 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4829 - val_accuracy: 0.7656\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4828 - val_accuracy: 0.7656\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.7708 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4623 - accuracy: 0.7691 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7708 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7691 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4827 - val_accuracy: 0.7656\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7656\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4826 - val_accuracy: 0.7708\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.7708 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7691 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7691 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7691 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7708 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7691 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7691 - val_loss: 0.4825 - val_accuracy: 0.7708\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7691 - val_loss: 0.4824 - val_accuracy: 0.7708\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4613 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7691 - val_loss: 0.4823 - val_accuracy: 0.7708\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.4822 - val_accuracy: 0.7708\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7691 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.4821 - val_accuracy: 0.7656\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7691 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7691 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4820 - val_accuracy: 0.7708\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7691 - val_loss: 0.4819 - val_accuracy: 0.7708\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.4818 - val_accuracy: 0.7708\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7708 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7691 - val_loss: 0.4817 - val_accuracy: 0.7708\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7691 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7726 - val_loss: 0.4816 - val_accuracy: 0.7708\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7726 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7743 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7708\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7656\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7708\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7743 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.7743 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7743 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7743 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7778 - val_loss: 0.4813 - val_accuracy: 0.7604\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7778 - val_loss: 0.4814 - val_accuracy: 0.7656\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7760 - val_loss: 0.4814 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18327419be0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 13ms/step - loss: 0.7470 - accuracy: 0.4514 - val_loss: 0.7407 - val_accuracy: 0.4271\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7377 - accuracy: 0.4618 - val_loss: 0.7325 - val_accuracy: 0.4427\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7292 - accuracy: 0.4618 - val_loss: 0.7250 - val_accuracy: 0.4531\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7214 - accuracy: 0.4705 - val_loss: 0.7183 - val_accuracy: 0.4792\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7143 - accuracy: 0.4931 - val_loss: 0.7121 - val_accuracy: 0.5104\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7077 - accuracy: 0.5069 - val_loss: 0.7064 - val_accuracy: 0.5521\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.5208 - val_loss: 0.7012 - val_accuracy: 0.5573\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.5347 - val_loss: 0.6964 - val_accuracy: 0.5677\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6909 - accuracy: 0.5451 - val_loss: 0.6920 - val_accuracy: 0.5729\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6861 - accuracy: 0.5451 - val_loss: 0.6879 - val_accuracy: 0.5833\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6816 - accuracy: 0.5469 - val_loss: 0.6841 - val_accuracy: 0.5885\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6775 - accuracy: 0.5642 - val_loss: 0.6807 - val_accuracy: 0.5938\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6736 - accuracy: 0.5747 - val_loss: 0.6775 - val_accuracy: 0.6042\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6700 - accuracy: 0.5851 - val_loss: 0.6745 - val_accuracy: 0.6146\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6666 - accuracy: 0.5920 - val_loss: 0.6718 - val_accuracy: 0.6302\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.6059 - val_loss: 0.6692 - val_accuracy: 0.6354\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6111 - val_loss: 0.6667 - val_accuracy: 0.6302\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6576 - accuracy: 0.6146 - val_loss: 0.6645 - val_accuracy: 0.6354\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6549 - accuracy: 0.6198 - val_loss: 0.6624 - val_accuracy: 0.6406\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.6267 - val_loss: 0.6604 - val_accuracy: 0.6458\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6500 - accuracy: 0.6285 - val_loss: 0.6585 - val_accuracy: 0.6354\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6285 - val_loss: 0.6567 - val_accuracy: 0.6510\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6455 - accuracy: 0.6319 - val_loss: 0.6550 - val_accuracy: 0.6510\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.6389 - val_loss: 0.6533 - val_accuracy: 0.6562\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.6441 - val_loss: 0.6517 - val_accuracy: 0.6667\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6395 - accuracy: 0.6528 - val_loss: 0.6502 - val_accuracy: 0.6823\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.6597 - val_loss: 0.6488 - val_accuracy: 0.6823\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6359 - accuracy: 0.6667 - val_loss: 0.6475 - val_accuracy: 0.6823\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6342 - accuracy: 0.6719 - val_loss: 0.6462 - val_accuracy: 0.6771\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6326 - accuracy: 0.6719 - val_loss: 0.6449 - val_accuracy: 0.6771\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.6311 - accuracy: 0.6771 - val_loss: 0.6438 - val_accuracy: 0.6667\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.6806 - val_loss: 0.6426 - val_accuracy: 0.6719\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6282 - accuracy: 0.6823 - val_loss: 0.6416 - val_accuracy: 0.6719\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6268 - accuracy: 0.6823 - val_loss: 0.6405 - val_accuracy: 0.6615\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6255 - accuracy: 0.6858 - val_loss: 0.6395 - val_accuracy: 0.6667\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.6892 - val_loss: 0.6385 - val_accuracy: 0.6719\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.6229 - accuracy: 0.6858 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6217 - accuracy: 0.6892 - val_loss: 0.6367 - val_accuracy: 0.6667\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6205 - accuracy: 0.6892 - val_loss: 0.6358 - val_accuracy: 0.6615\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.6193 - accuracy: 0.6962 - val_loss: 0.6350 - val_accuracy: 0.6667\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.6182 - accuracy: 0.7014 - val_loss: 0.6341 - val_accuracy: 0.6667\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6171 - accuracy: 0.7083 - val_loss: 0.6333 - val_accuracy: 0.6667\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6159 - accuracy: 0.7083 - val_loss: 0.6324 - val_accuracy: 0.6615\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6148 - accuracy: 0.7101 - val_loss: 0.6316 - val_accuracy: 0.6615\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.7101 - val_loss: 0.6308 - val_accuracy: 0.6615\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.7049 - val_loss: 0.6300 - val_accuracy: 0.6615\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7014 - val_loss: 0.6292 - val_accuracy: 0.6615\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.6997 - val_loss: 0.6284 - val_accuracy: 0.6615\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6097 - accuracy: 0.6997 - val_loss: 0.6277 - val_accuracy: 0.6667\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6087 - accuracy: 0.6997 - val_loss: 0.6269 - val_accuracy: 0.6719\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6077 - accuracy: 0.6979 - val_loss: 0.6262 - val_accuracy: 0.6615\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6068 - accuracy: 0.6962 - val_loss: 0.6254 - val_accuracy: 0.6615\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6058 - accuracy: 0.6944 - val_loss: 0.6247 - val_accuracy: 0.6615\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6910 - val_loss: 0.6240 - val_accuracy: 0.6615\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.6910 - val_loss: 0.6233 - val_accuracy: 0.6667\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.6910 - val_loss: 0.6226 - val_accuracy: 0.6667\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6023 - accuracy: 0.6910 - val_loss: 0.6219 - val_accuracy: 0.6771\n",
      "Epoch 58/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6014 - accuracy: 0.6892 - val_loss: 0.6213 - val_accuracy: 0.6823\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6006 - accuracy: 0.6892 - val_loss: 0.6206 - val_accuracy: 0.6823\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5997 - accuracy: 0.6910 - val_loss: 0.6200 - val_accuracy: 0.6823\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5989 - accuracy: 0.6892 - val_loss: 0.6193 - val_accuracy: 0.6823\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5981 - accuracy: 0.6892 - val_loss: 0.6186 - val_accuracy: 0.6771\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5972 - accuracy: 0.6892 - val_loss: 0.6180 - val_accuracy: 0.6771\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.6892 - val_loss: 0.6173 - val_accuracy: 0.6771\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6892 - val_loss: 0.6167 - val_accuracy: 0.6771\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6892 - val_loss: 0.6161 - val_accuracy: 0.6771\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.6892 - val_loss: 0.6154 - val_accuracy: 0.6771\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5933 - accuracy: 0.6892 - val_loss: 0.6148 - val_accuracy: 0.6771\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5926 - accuracy: 0.6892 - val_loss: 0.6142 - val_accuracy: 0.6771\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.6892 - val_loss: 0.6136 - val_accuracy: 0.6771\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6892 - val_loss: 0.6130 - val_accuracy: 0.6771\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6892 - val_loss: 0.6124 - val_accuracy: 0.6771\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5894 - accuracy: 0.6892 - val_loss: 0.6118 - val_accuracy: 0.6771\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5886 - accuracy: 0.6892 - val_loss: 0.6112 - val_accuracy: 0.6771\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5879 - accuracy: 0.6892 - val_loss: 0.6106 - val_accuracy: 0.6771\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.6892 - val_loss: 0.6100 - val_accuracy: 0.6771\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.6910 - val_loss: 0.6095 - val_accuracy: 0.6823\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5856 - accuracy: 0.6910 - val_loss: 0.6089 - val_accuracy: 0.6823\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5848 - accuracy: 0.6892 - val_loss: 0.6083 - val_accuracy: 0.6823\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.6892 - val_loss: 0.6077 - val_accuracy: 0.6823\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.6927 - val_loss: 0.6072 - val_accuracy: 0.6823\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5825 - accuracy: 0.6944 - val_loss: 0.6066 - val_accuracy: 0.6823\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5818 - accuracy: 0.6944 - val_loss: 0.6061 - val_accuracy: 0.6823\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.6944 - val_loss: 0.6055 - val_accuracy: 0.6823\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5802 - accuracy: 0.6962 - val_loss: 0.6050 - val_accuracy: 0.6823\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.6962 - val_loss: 0.6044 - val_accuracy: 0.6823\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5788 - accuracy: 0.6962 - val_loss: 0.6039 - val_accuracy: 0.6823\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5781 - accuracy: 0.6979 - val_loss: 0.6033 - val_accuracy: 0.6823\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5773 - accuracy: 0.6997 - val_loss: 0.6027 - val_accuracy: 0.6823\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.6997 - val_loss: 0.6021 - val_accuracy: 0.6875\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.7014 - val_loss: 0.6015 - val_accuracy: 0.6875\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5751 - accuracy: 0.7014 - val_loss: 0.6009 - val_accuracy: 0.6875\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5744 - accuracy: 0.7014 - val_loss: 0.6004 - val_accuracy: 0.6875\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5737 - accuracy: 0.7014 - val_loss: 0.5998 - val_accuracy: 0.6875\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5729 - accuracy: 0.7014 - val_loss: 0.5992 - val_accuracy: 0.6875\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7014 - val_loss: 0.5986 - val_accuracy: 0.6875\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5715 - accuracy: 0.7014 - val_loss: 0.5981 - val_accuracy: 0.6875\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5708 - accuracy: 0.7014 - val_loss: 0.5975 - val_accuracy: 0.6875\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.7014 - val_loss: 0.5970 - val_accuracy: 0.6823\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5693 - accuracy: 0.7014 - val_loss: 0.5964 - val_accuracy: 0.6823\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5686 - accuracy: 0.7014 - val_loss: 0.5958 - val_accuracy: 0.6823\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5679 - accuracy: 0.7014 - val_loss: 0.5952 - val_accuracy: 0.6823\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5672 - accuracy: 0.7031 - val_loss: 0.5947 - val_accuracy: 0.6771\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5665 - accuracy: 0.7031 - val_loss: 0.5941 - val_accuracy: 0.6771\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5657 - accuracy: 0.7031 - val_loss: 0.5935 - val_accuracy: 0.6771\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5650 - accuracy: 0.7031 - val_loss: 0.5929 - val_accuracy: 0.6771\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7049 - val_loss: 0.5923 - val_accuracy: 0.6771\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7031 - val_loss: 0.5917 - val_accuracy: 0.6771\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7049 - val_loss: 0.5910 - val_accuracy: 0.6771\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7066 - val_loss: 0.5904 - val_accuracy: 0.6771\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.7066 - val_loss: 0.5898 - val_accuracy: 0.6771\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5605 - accuracy: 0.7066 - val_loss: 0.5892 - val_accuracy: 0.6771\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7066 - val_loss: 0.5886 - val_accuracy: 0.6823\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.7066 - val_loss: 0.5880 - val_accuracy: 0.6823\n",
      "Epoch 115/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7083 - val_loss: 0.5874 - val_accuracy: 0.6823\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7083 - val_loss: 0.5868 - val_accuracy: 0.6823\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7083 - val_loss: 0.5862 - val_accuracy: 0.6823\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.7083 - val_loss: 0.5855 - val_accuracy: 0.6823\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7083 - val_loss: 0.5849 - val_accuracy: 0.6823\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7083 - val_loss: 0.5843 - val_accuracy: 0.6823\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5537 - accuracy: 0.7083 - val_loss: 0.5836 - val_accuracy: 0.6823\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.7101 - val_loss: 0.5830 - val_accuracy: 0.6823\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7101 - val_loss: 0.5824 - val_accuracy: 0.6823\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5514 - accuracy: 0.7101 - val_loss: 0.5817 - val_accuracy: 0.6823\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7101 - val_loss: 0.5811 - val_accuracy: 0.6823\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5499 - accuracy: 0.7101 - val_loss: 0.5805 - val_accuracy: 0.6823\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7118 - val_loss: 0.5798 - val_accuracy: 0.6823\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5484 - accuracy: 0.7118 - val_loss: 0.5792 - val_accuracy: 0.6823\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5476 - accuracy: 0.7118 - val_loss: 0.5786 - val_accuracy: 0.6823\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7118 - val_loss: 0.5780 - val_accuracy: 0.6823\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5462 - accuracy: 0.7118 - val_loss: 0.5774 - val_accuracy: 0.6823\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7118 - val_loss: 0.5768 - val_accuracy: 0.6823\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7118 - val_loss: 0.5762 - val_accuracy: 0.6875\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7118 - val_loss: 0.5756 - val_accuracy: 0.6875\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.7118 - val_loss: 0.5750 - val_accuracy: 0.6875\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7153 - val_loss: 0.5745 - val_accuracy: 0.6875\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5420 - accuracy: 0.7170 - val_loss: 0.5739 - val_accuracy: 0.6875\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5413 - accuracy: 0.7170 - val_loss: 0.5733 - val_accuracy: 0.6927\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7170 - val_loss: 0.5728 - val_accuracy: 0.6927\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5399 - accuracy: 0.7153 - val_loss: 0.5722 - val_accuracy: 0.6927\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5392 - accuracy: 0.7153 - val_loss: 0.5717 - val_accuracy: 0.6979\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7170 - val_loss: 0.5712 - val_accuracy: 0.6979\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.7170 - val_loss: 0.5706 - val_accuracy: 0.7031\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7188 - val_loss: 0.5701 - val_accuracy: 0.7083\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5365 - accuracy: 0.7188 - val_loss: 0.5696 - val_accuracy: 0.7083\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.7188 - val_loss: 0.5691 - val_accuracy: 0.7083\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7188 - val_loss: 0.5686 - val_accuracy: 0.7083\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7222 - val_loss: 0.5681 - val_accuracy: 0.7083\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5340 - accuracy: 0.7240 - val_loss: 0.5676 - val_accuracy: 0.7083\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7274 - val_loss: 0.5670 - val_accuracy: 0.7083\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5327 - accuracy: 0.7274 - val_loss: 0.5665 - val_accuracy: 0.7083\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.7292 - val_loss: 0.5660 - val_accuracy: 0.7083\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5315 - accuracy: 0.7309 - val_loss: 0.5655 - val_accuracy: 0.7083\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5309 - accuracy: 0.7309 - val_loss: 0.5650 - val_accuracy: 0.7083\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5302 - accuracy: 0.7309 - val_loss: 0.5645 - val_accuracy: 0.7083\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7292 - val_loss: 0.5640 - val_accuracy: 0.7083\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7309 - val_loss: 0.5635 - val_accuracy: 0.7083\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7309 - val_loss: 0.5630 - val_accuracy: 0.7083\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5277 - accuracy: 0.7309 - val_loss: 0.5624 - val_accuracy: 0.7083\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7309 - val_loss: 0.5619 - val_accuracy: 0.7083\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7344 - val_loss: 0.5614 - val_accuracy: 0.7135\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7344 - val_loss: 0.5609 - val_accuracy: 0.7135\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7344 - val_loss: 0.5604 - val_accuracy: 0.7135\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7361 - val_loss: 0.5599 - val_accuracy: 0.7135\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.7378 - val_loss: 0.5594 - val_accuracy: 0.7135\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5232 - accuracy: 0.7396 - val_loss: 0.5589 - val_accuracy: 0.7135\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7396 - val_loss: 0.5584 - val_accuracy: 0.7135\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7413 - val_loss: 0.5579 - val_accuracy: 0.7135\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.7413 - val_loss: 0.5574 - val_accuracy: 0.7135\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.7413 - val_loss: 0.5569 - val_accuracy: 0.7135\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7413 - val_loss: 0.5564 - val_accuracy: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5195 - accuracy: 0.7413 - val_loss: 0.5559 - val_accuracy: 0.7135\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7431 - val_loss: 0.5554 - val_accuracy: 0.7135\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7448 - val_loss: 0.5549 - val_accuracy: 0.7135\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7431 - val_loss: 0.5544 - val_accuracy: 0.7135\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7431 - val_loss: 0.5539 - val_accuracy: 0.7135\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7431 - val_loss: 0.5534 - val_accuracy: 0.7083\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7431 - val_loss: 0.5529 - val_accuracy: 0.7083\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7431 - val_loss: 0.5524 - val_accuracy: 0.7083\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5146 - accuracy: 0.7448 - val_loss: 0.5519 - val_accuracy: 0.7031\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7431 - val_loss: 0.5515 - val_accuracy: 0.7031\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7431 - val_loss: 0.5510 - val_accuracy: 0.7031\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5129 - accuracy: 0.7448 - val_loss: 0.5505 - val_accuracy: 0.7031\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7465 - val_loss: 0.5501 - val_accuracy: 0.7031\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5118 - accuracy: 0.7465 - val_loss: 0.5496 - val_accuracy: 0.7031\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7448 - val_loss: 0.5491 - val_accuracy: 0.7031\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5106 - accuracy: 0.7448 - val_loss: 0.5487 - val_accuracy: 0.7031\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7465 - val_loss: 0.5483 - val_accuracy: 0.7031\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7448 - val_loss: 0.5478 - val_accuracy: 0.7083\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5090 - accuracy: 0.7448 - val_loss: 0.5474 - val_accuracy: 0.7083\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7448 - val_loss: 0.5469 - val_accuracy: 0.7083\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7448 - val_loss: 0.5465 - val_accuracy: 0.7083\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7448 - val_loss: 0.5461 - val_accuracy: 0.7083\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7465 - val_loss: 0.5456 - val_accuracy: 0.7083\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7465 - val_loss: 0.5452 - val_accuracy: 0.7083\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7448 - val_loss: 0.5448 - val_accuracy: 0.7135\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7431 - val_loss: 0.5444 - val_accuracy: 0.7135\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7413 - val_loss: 0.5439 - val_accuracy: 0.7135\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7413 - val_loss: 0.5435 - val_accuracy: 0.7135\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7413 - val_loss: 0.5431 - val_accuracy: 0.7083\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7431 - val_loss: 0.5427 - val_accuracy: 0.7135\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7431 - val_loss: 0.5422 - val_accuracy: 0.7188\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7448 - val_loss: 0.5418 - val_accuracy: 0.7188\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7448 - val_loss: 0.5414 - val_accuracy: 0.7188\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7448 - val_loss: 0.5410 - val_accuracy: 0.7188\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7448 - val_loss: 0.5406 - val_accuracy: 0.7188\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5001 - accuracy: 0.7448 - val_loss: 0.5402 - val_accuracy: 0.7188\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7465 - val_loss: 0.5398 - val_accuracy: 0.7188\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4991 - accuracy: 0.7483 - val_loss: 0.5394 - val_accuracy: 0.7188\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.7483 - val_loss: 0.5390 - val_accuracy: 0.7188\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7500 - val_loss: 0.5386 - val_accuracy: 0.7188\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7483 - val_loss: 0.5382 - val_accuracy: 0.7188\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.7483 - val_loss: 0.5378 - val_accuracy: 0.7240\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7500 - val_loss: 0.5374 - val_accuracy: 0.7240\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7500 - val_loss: 0.5370 - val_accuracy: 0.7240\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7500 - val_loss: 0.5367 - val_accuracy: 0.7240\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.7517 - val_loss: 0.5363 - val_accuracy: 0.7240\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7517 - val_loss: 0.5359 - val_accuracy: 0.7240\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.7535 - val_loss: 0.5355 - val_accuracy: 0.7240\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7535 - val_loss: 0.5352 - val_accuracy: 0.7240\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7552 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7552 - val_loss: 0.5345 - val_accuracy: 0.7240\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4924 - accuracy: 0.7569 - val_loss: 0.5341 - val_accuracy: 0.7240\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4919 - accuracy: 0.7569 - val_loss: 0.5338 - val_accuracy: 0.7240\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7569 - val_loss: 0.5334 - val_accuracy: 0.7240\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4911 - accuracy: 0.7587 - val_loss: 0.5331 - val_accuracy: 0.7240\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7587 - val_loss: 0.5328 - val_accuracy: 0.7240\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7587 - val_loss: 0.5325 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7604 - val_loss: 0.5321 - val_accuracy: 0.7292\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7587 - val_loss: 0.5318 - val_accuracy: 0.7292\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7587 - val_loss: 0.5315 - val_accuracy: 0.7344\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7587 - val_loss: 0.5312 - val_accuracy: 0.7344\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4880 - accuracy: 0.7569 - val_loss: 0.5309 - val_accuracy: 0.7344\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4877 - accuracy: 0.7587 - val_loss: 0.5306 - val_accuracy: 0.7344\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4872 - accuracy: 0.7587 - val_loss: 0.5303 - val_accuracy: 0.7396\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7587 - val_loss: 0.5300 - val_accuracy: 0.7396\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4864 - accuracy: 0.7587 - val_loss: 0.5297 - val_accuracy: 0.7396\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7587 - val_loss: 0.5295 - val_accuracy: 0.7344\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.7604 - val_loss: 0.5292 - val_accuracy: 0.7344\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7604 - val_loss: 0.5289 - val_accuracy: 0.7344\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7639 - val_loss: 0.5287 - val_accuracy: 0.7344\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7639 - val_loss: 0.5284 - val_accuracy: 0.7344\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7344\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7639 - val_loss: 0.5280 - val_accuracy: 0.7344\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.5277 - val_accuracy: 0.7344\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.7639 - val_loss: 0.5275 - val_accuracy: 0.7344\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7639 - val_loss: 0.5273 - val_accuracy: 0.7344\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7639 - val_loss: 0.5271 - val_accuracy: 0.7344\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.5269 - val_accuracy: 0.7344\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.5264 - val_accuracy: 0.7396\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7639 - val_loss: 0.5262 - val_accuracy: 0.7396\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7639 - val_loss: 0.5260 - val_accuracy: 0.7396\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7639 - val_loss: 0.5258 - val_accuracy: 0.7396\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4797 - accuracy: 0.7639 - val_loss: 0.5256 - val_accuracy: 0.7396\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.5255 - val_accuracy: 0.7396\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.7656 - val_loss: 0.5253 - val_accuracy: 0.7396\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7396\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7656 - val_loss: 0.5249 - val_accuracy: 0.7396\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.5248 - val_accuracy: 0.7396\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7656 - val_loss: 0.5246 - val_accuracy: 0.7396\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7656 - val_loss: 0.5244 - val_accuracy: 0.7448\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7656 - val_loss: 0.5243 - val_accuracy: 0.7448\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4764 - accuracy: 0.7639 - val_loss: 0.5241 - val_accuracy: 0.7448\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4761 - accuracy: 0.7639 - val_loss: 0.5239 - val_accuracy: 0.7448\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7656 - val_loss: 0.5237 - val_accuracy: 0.7448\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7656 - val_loss: 0.5236 - val_accuracy: 0.7448\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7639 - val_loss: 0.5234 - val_accuracy: 0.7448\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7639 - val_loss: 0.5232 - val_accuracy: 0.7448\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7639 - val_loss: 0.5231 - val_accuracy: 0.7448\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7639 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7639 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7639 - val_loss: 0.5226 - val_accuracy: 0.7500\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7656 - val_loss: 0.5224 - val_accuracy: 0.7500\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7656 - val_loss: 0.5223 - val_accuracy: 0.7500\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4725 - accuracy: 0.7656 - val_loss: 0.5221 - val_accuracy: 0.7500\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4722 - accuracy: 0.7639 - val_loss: 0.5220 - val_accuracy: 0.7500\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4719 - accuracy: 0.7656 - val_loss: 0.5218 - val_accuracy: 0.7500\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.5217 - val_accuracy: 0.7500\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7656 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.7691 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7656 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4704 - accuracy: 0.7674 - val_loss: 0.5211 - val_accuracy: 0.7396\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7396\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4698 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4696 - accuracy: 0.7674 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7674 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7674 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7674 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.7674 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7674 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7674 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7691 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7691 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7691 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.7691 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7691 - val_loss: 0.5194 - val_accuracy: 0.7396\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7396\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7726 - val_loss: 0.5191 - val_accuracy: 0.7396\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.7726 - val_loss: 0.5190 - val_accuracy: 0.7396\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4652 - accuracy: 0.7726 - val_loss: 0.5190 - val_accuracy: 0.7448\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.7726 - val_loss: 0.5189 - val_accuracy: 0.7448\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7448\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.7743 - val_loss: 0.5187 - val_accuracy: 0.7448\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7743 - val_loss: 0.5186 - val_accuracy: 0.7448\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.5185 - val_accuracy: 0.7448\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7760 - val_loss: 0.5184 - val_accuracy: 0.7448\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.7778 - val_loss: 0.5183 - val_accuracy: 0.7448\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7778 - val_loss: 0.5182 - val_accuracy: 0.7448\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.5181 - val_accuracy: 0.7448\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.7778 - val_loss: 0.5180 - val_accuracy: 0.7448\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7760 - val_loss: 0.5179 - val_accuracy: 0.7448\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.5178 - val_accuracy: 0.7448\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.5177 - val_accuracy: 0.7448\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.5176 - val_accuracy: 0.7448\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.5175 - val_accuracy: 0.7448\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7778 - val_loss: 0.5174 - val_accuracy: 0.7448\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.5173 - val_accuracy: 0.7448\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.5172 - val_accuracy: 0.7396\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7760 - val_loss: 0.5171 - val_accuracy: 0.7396\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7795 - val_loss: 0.5170 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.5169 - val_accuracy: 0.7500\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.5168 - val_accuracy: 0.7552\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7778 - val_loss: 0.5167 - val_accuracy: 0.7552\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7795 - val_loss: 0.5166 - val_accuracy: 0.7500\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4592 - accuracy: 0.7865 - val_loss: 0.5165 - val_accuracy: 0.7500\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7865 - val_loss: 0.5164 - val_accuracy: 0.7500\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7865 - val_loss: 0.5163 - val_accuracy: 0.7500\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7865 - val_loss: 0.5162 - val_accuracy: 0.7448\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7882 - val_loss: 0.5161 - val_accuracy: 0.7448\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7448\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4580 - accuracy: 0.7847 - val_loss: 0.5160 - val_accuracy: 0.7396\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7865 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.7865 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.7899 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7865 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7882 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7882 - val_loss: 0.5154 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7865 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7865 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7847 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7865 - val_loss: 0.5151 - val_accuracy: 0.7396\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7865 - val_loss: 0.5150 - val_accuracy: 0.7396\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7847 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.7882 - val_loss: 0.5149 - val_accuracy: 0.7396\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7882 - val_loss: 0.5148 - val_accuracy: 0.7448\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7899 - val_loss: 0.5148 - val_accuracy: 0.7500\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.7882 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4544 - accuracy: 0.7899 - val_loss: 0.5147 - val_accuracy: 0.7500\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7500\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7882 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7865 - val_loss: 0.5146 - val_accuracy: 0.7552\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7865 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7847 - val_loss: 0.5145 - val_accuracy: 0.7552\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.7865 - val_loss: 0.5144 - val_accuracy: 0.7552\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.7882 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7865 - val_loss: 0.5143 - val_accuracy: 0.7500\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4528 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7500\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7552\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.5142 - val_accuracy: 0.7604\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7882 - val_loss: 0.5141 - val_accuracy: 0.7656\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7917 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7917 - val_loss: 0.5140 - val_accuracy: 0.7656\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7934 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.7917 - val_loss: 0.5139 - val_accuracy: 0.7708\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.7899 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7934 - val_loss: 0.5138 - val_accuracy: 0.7708\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7899 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.7899 - val_loss: 0.5137 - val_accuracy: 0.7708\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7917 - val_loss: 0.5137 - val_accuracy: 0.7760\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7917 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7934 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7951 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7934 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7760\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7934 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7969 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7969 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4475 - accuracy: 0.7969 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7951 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7951 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7969 - val_loss: 0.5130 - val_accuracy: 0.7708\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7708\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7951 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7951 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.7969 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7969 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7951 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7969 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8003 - val_loss: 0.5126 - val_accuracy: 0.7656\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7969 - val_loss: 0.5126 - val_accuracy: 0.7604\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7986 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8003 - val_loss: 0.5125 - val_accuracy: 0.7604\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7986 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7604\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8003 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8003 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.8003 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7604\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7969 - val_loss: 0.5122 - val_accuracy: 0.7604\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7604\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7969 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7951 - val_loss: 0.5121 - val_accuracy: 0.7552\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7934 - val_loss: 0.5120 - val_accuracy: 0.7552\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7934 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7934 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7934 - val_loss: 0.5119 - val_accuracy: 0.7552\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7934 - val_loss: 0.5118 - val_accuracy: 0.7552\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7934 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7934 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7969 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7934 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7969 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7951 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4403 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4401 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7934 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4384 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7951 - val_loss: 0.5113 - val_accuracy: 0.7552\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4367 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4366 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4360 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7951 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7951 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4348 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7969 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4344 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5114 - val_accuracy: 0.7552\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4330 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7969 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.8003 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7552\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7986 - val_loss: 0.5115 - val_accuracy: 0.7604\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4324 - accuracy: 0.7969 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7969 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4320 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4314 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7604\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7986 - val_loss: 0.5116 - val_accuracy: 0.7552\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7552\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7500\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8003 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5117 - val_accuracy: 0.7448\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5118 - val_accuracy: 0.7396\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7986 - val_loss: 0.5119 - val_accuracy: 0.7396\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8003 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.7986 - val_loss: 0.5120 - val_accuracy: 0.7396\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.5121 - val_accuracy: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7986 - val_loss: 0.5121 - val_accuracy: 0.7396\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.7986 - val_loss: 0.5122 - val_accuracy: 0.7396\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7986 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8021 - val_loss: 0.5123 - val_accuracy: 0.7396\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8021 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.5124 - val_accuracy: 0.7396\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8021 - val_loss: 0.5125 - val_accuracy: 0.7396\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8021 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8021 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5129 - val_accuracy: 0.7292\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8021 - val_loss: 0.5130 - val_accuracy: 0.7292\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8038 - val_loss: 0.5131 - val_accuracy: 0.7292\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7292\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8038 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8038 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8038 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8038 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8038 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8021 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8038 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8003 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8021 - val_loss: 0.5138 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.8021 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4258 - accuracy: 0.8021 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4255 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4253 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4252 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4251 - accuracy: 0.8003 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4250 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8003 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7344\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5146 - val_accuracy: 0.7344\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8003 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7344\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4245 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7344\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8021 - val_loss: 0.5148 - val_accuracy: 0.7344\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7344\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7344\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5149 - val_accuracy: 0.7344\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4242 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4241 - accuracy: 0.8021 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8021 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4234 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4235 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8038 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8038 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4230 - accuracy: 0.8038 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4229 - accuracy: 0.8038 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.8056 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8056 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4227 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8038 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4224 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8056 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8056 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8056 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8056 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8056 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8056 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4219 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4218 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8056 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8056 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4215 - accuracy: 0.8056 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8056 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8056 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8056 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4212 - accuracy: 0.8056 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4211 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4211 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4210 - accuracy: 0.8056 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4208 - accuracy: 0.8056 - val_loss: 0.5171 - val_accuracy: 0.7292\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.8056 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4207 - accuracy: 0.8056 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4207 - accuracy: 0.8073 - val_loss: 0.5172 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8073 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8073 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8073 - val_loss: 0.5172 - val_accuracy: 0.7292\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4204 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4204 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4203 - accuracy: 0.8073 - val_loss: 0.5173 - val_accuracy: 0.7292\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4203 - accuracy: 0.8073 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4203 - accuracy: 0.8073 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4202 - accuracy: 0.8073 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4202 - accuracy: 0.8073 - val_loss: 0.5174 - val_accuracy: 0.7292\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4202 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4200 - accuracy: 0.8090 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 0.4200 - accuracy: 0.8073 - val_loss: 0.5175 - val_accuracy: 0.7292\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4200 - accuracy: 0.8073 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 0.4200 - accuracy: 0.8090 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8090 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4198 - accuracy: 0.8090 - val_loss: 0.5176 - val_accuracy: 0.7292\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4198 - accuracy: 0.8108 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4197 - accuracy: 0.8108 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4197 - accuracy: 0.8125 - val_loss: 0.5177 - val_accuracy: 0.7292\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4196 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4195 - accuracy: 0.8108 - val_loss: 0.5178 - val_accuracy: 0.7292\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4194 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4194 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4194 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4193 - accuracy: 0.8125 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4193 - accuracy: 0.8108 - val_loss: 0.5179 - val_accuracy: 0.7292\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 0.4192 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4192 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4191 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4191 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8125 - val_loss: 0.5180 - val_accuracy: 0.7292\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8108 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.8125 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4189 - accuracy: 0.8125 - val_loss: 0.5181 - val_accuracy: 0.7292\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8108 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.8125 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4187 - accuracy: 0.8125 - val_loss: 0.5182 - val_accuracy: 0.7292\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4187 - accuracy: 0.8108 - val_loss: 0.5183 - val_accuracy: 0.7292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8108 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4186 - accuracy: 0.8108 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4186 - accuracy: 0.8108 - val_loss: 0.5183 - val_accuracy: 0.7292\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8125 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4185 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.5184 - val_accuracy: 0.7240\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4184 - accuracy: 0.8108 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8108 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4183 - accuracy: 0.8090 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.5185 - val_accuracy: 0.7240\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4182 - accuracy: 0.8108 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.5186 - val_accuracy: 0.7240\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 0.4181 - accuracy: 0.8090 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4181 - accuracy: 0.8108 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4180 - accuracy: 0.8108 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 0.4180 - accuracy: 0.8108 - val_loss: 0.5187 - val_accuracy: 0.7240\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.8108 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8125 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4179 - accuracy: 0.8108 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4178 - accuracy: 0.8108 - val_loss: 0.5188 - val_accuracy: 0.7240\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.8108 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8108 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.8125 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4178 - accuracy: 0.8125 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.8108 - val_loss: 0.5189 - val_accuracy: 0.7240\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 0.4177 - accuracy: 0.8142 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4177 - accuracy: 0.8125 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8125 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8142 - val_loss: 0.5190 - val_accuracy: 0.7240\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5191 - val_accuracy: 0.7240\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8142 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8125 - val_loss: 0.5192 - val_accuracy: 0.7240\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8142 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8142 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8142 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4173 - accuracy: 0.8142 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8142 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 0.7240\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8160 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8142 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.8160 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8177 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8160 - val_loss: 0.5194 - val_accuracy: 0.7240\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8160 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8177 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8160 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4170 - accuracy: 0.8177 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8160 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8177 - val_loss: 0.5195 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8177 - val_loss: 0.5195 - val_accuracy: 0.7240\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8177 - val_loss: 0.5196 - val_accuracy: 0.7240\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8177 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8177 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8177 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8177 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8177 - val_loss: 0.5197 - val_accuracy: 0.7240\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4166 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4165 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4164 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4164 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.5198 - val_accuracy: 0.7240\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4163 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4162 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8177 - val_loss: 0.5199 - val_accuracy: 0.7240\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4160 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4159 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8177 - val_loss: 0.5200 - val_accuracy: 0.7240\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8177 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8177 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8177 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8177 - val_loss: 0.5201 - val_accuracy: 0.7240\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8177 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8177 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.5202 - val_accuracy: 0.7240\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4154 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4154 - accuracy: 0.8177 - val_loss: 0.5203 - val_accuracy: 0.7240\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8177 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8177 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8177 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8177 - val_loss: 0.5204 - val_accuracy: 0.7240\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8177 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8177 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8177 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5205 - val_accuracy: 0.7240\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5206 - val_accuracy: 0.7240\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4151 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7240\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4148 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7240\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8177 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8177 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.5209 - val_accuracy: 0.7240\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4145 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4145 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.5210 - val_accuracy: 0.7240\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4144 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4143 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4142 - accuracy: 0.8177 - val_loss: 0.5211 - val_accuracy: 0.7240\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4140 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4139 - accuracy: 0.8177 - val_loss: 0.5212 - val_accuracy: 0.7240\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8177 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8177 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8177 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4138 - accuracy: 0.8177 - val_loss: 0.5213 - val_accuracy: 0.7240\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8194 - val_loss: 0.5214 - val_accuracy: 0.7240\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8177 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4137 - accuracy: 0.8177 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8194 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.8177 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8194 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8177 - val_loss: 0.5215 - val_accuracy: 0.7240\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4135 - accuracy: 0.8177 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4135 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8177 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8194 - val_loss: 0.5216 - val_accuracy: 0.7240\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8194 - val_loss: 0.5217 - val_accuracy: 0.7240\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8212 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8194 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4132 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5218 - val_accuracy: 0.7240\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8194 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4130 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5219 - val_accuracy: 0.7240\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5220 - val_accuracy: 0.7240\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8212 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8194 - val_loss: 0.5221 - val_accuracy: 0.7240\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4129 - accuracy: 0.8212 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8194 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8194 - val_loss: 0.5222 - val_accuracy: 0.7240\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4128 - accuracy: 0.8194 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8212 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8194 - val_loss: 0.5223 - val_accuracy: 0.7240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8194 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8212 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8194 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4127 - accuracy: 0.8194 - val_loss: 0.5223 - val_accuracy: 0.7240\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.5224 - val_accuracy: 0.7240\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8212 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4126 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8212 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8194 - val_loss: 0.5225 - val_accuracy: 0.7240\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8212 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8194 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8194 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8212 - val_loss: 0.5226 - val_accuracy: 0.7240\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8212 - val_loss: 0.5227 - val_accuracy: 0.7240\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8212 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4122 - accuracy: 0.8212 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8212 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8194 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.8212 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8177 - val_loss: 0.5228 - val_accuracy: 0.7240\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8229 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8212 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4120 - accuracy: 0.8212 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8194 - val_loss: 0.5229 - val_accuracy: 0.7240\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8212 - val_loss: 0.5230 - val_accuracy: 0.7240\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8212 - val_loss: 0.5231 - val_accuracy: 0.7240\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5232 - val_accuracy: 0.7240\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8212 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8212 - val_loss: 0.5233 - val_accuracy: 0.7240\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8212 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 1083/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8212 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8212 - val_loss: 0.5234 - val_accuracy: 0.7240\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4116 - accuracy: 0.8194 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8177 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8194 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8212 - val_loss: 0.5235 - val_accuracy: 0.7240\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8212 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4114 - accuracy: 0.8194 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8212 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4114 - accuracy: 0.8194 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4114 - accuracy: 0.8194 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8212 - val_loss: 0.5236 - val_accuracy: 0.7240\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.8212 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4113 - accuracy: 0.8177 - val_loss: 0.5237 - val_accuracy: 0.7240\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.5238 - val_accuracy: 0.7240\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4112 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4111 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8194 - val_loss: 0.5239 - val_accuracy: 0.7240\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8194 - val_loss: 0.5240 - val_accuracy: 0.7240\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8194 - val_loss: 0.5241 - val_accuracy: 0.7240\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4109 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5242 - val_accuracy: 0.7240\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5243 - val_accuracy: 0.7240\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5244 - val_accuracy: 0.7240\n",
      "Epoch 1139/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7188\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.5245 - val_accuracy: 0.7240\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4106 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5246 - val_accuracy: 0.7240\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7240\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4105 - accuracy: 0.8194 - val_loss: 0.5247 - val_accuracy: 0.7188\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7188\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7188\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5248 - val_accuracy: 0.7188\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4104 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5249 - val_accuracy: 0.7188\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8160 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5250 - val_accuracy: 0.7188\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8177 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.8194 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.5251 - val_accuracy: 0.7188\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8177 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8212 - val_loss: 0.5252 - val_accuracy: 0.7188\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8194 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8177 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8212 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8177 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8160 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4100 - accuracy: 0.8177 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8194 - val_loss: 0.5253 - val_accuracy: 0.7188\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8177 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8177 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8177 - val_loss: 0.5254 - val_accuracy: 0.7188\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8177 - val_loss: 0.5255 - val_accuracy: 0.7188\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8194 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 1195/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5256 - val_accuracy: 0.7188\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5257 - val_accuracy: 0.7188\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4098 - accuracy: 0.8177 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5258 - val_accuracy: 0.7188\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8160 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4097 - accuracy: 0.8177 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8160 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8177 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4096 - accuracy: 0.8177 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8194 - val_loss: 0.5259 - val_accuracy: 0.7188\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8177 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8177 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8177 - val_loss: 0.5260 - val_accuracy: 0.7188\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8177 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8160 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8160 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8160 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4095 - accuracy: 0.8177 - val_loss: 0.5261 - val_accuracy: 0.7188\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8177 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8177 - val_loss: 0.5262 - val_accuracy: 0.7188\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8160 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8177 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5263 - val_accuracy: 0.7188\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8177 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5264 - val_accuracy: 0.7188\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8160 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5265 - val_accuracy: 0.7188\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4092 - accuracy: 0.8160 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5266 - val_accuracy: 0.7188\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.8160 - val_loss: 0.5267 - val_accuracy: 0.7188\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8160 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4091 - accuracy: 0.8177 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5268 - val_accuracy: 0.7188\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4091 - accuracy: 0.8160 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8160 - val_loss: 0.5269 - val_accuracy: 0.7188\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4090 - accuracy: 0.8177 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8177 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 1251/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5270 - val_accuracy: 0.7188\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5271 - val_accuracy: 0.7188\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8177 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8160 - val_loss: 0.5272 - val_accuracy: 0.7188\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4088 - accuracy: 0.8160 - val_loss: 0.5273 - val_accuracy: 0.7188\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5274 - val_accuracy: 0.7188\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5274 - val_accuracy: 0.7188\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5275 - val_accuracy: 0.7188\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4087 - accuracy: 0.8160 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5276 - val_accuracy: 0.7188\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4086 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5277 - val_accuracy: 0.7188\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4085 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5278 - val_accuracy: 0.7188\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5279 - val_accuracy: 0.7188\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8177 - val_loss: 0.5280 - val_accuracy: 0.7188\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8177 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8160 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 1307/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4082 - accuracy: 0.8160 - val_loss: 0.5281 - val_accuracy: 0.7188\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5282 - val_accuracy: 0.7188\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5282 - val_accuracy: 0.7188\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5282 - val_accuracy: 0.7188\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4081 - accuracy: 0.8177 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5283 - val_accuracy: 0.7188\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4081 - accuracy: 0.8160 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5284 - val_accuracy: 0.7188\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8160 - val_loss: 0.5285 - val_accuracy: 0.7188\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8177 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5286 - val_accuracy: 0.7188\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4079 - accuracy: 0.8177 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4078 - accuracy: 0.8160 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4078 - accuracy: 0.8177 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8160 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4077 - accuracy: 0.8177 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4076 - accuracy: 0.8194 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8177 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4076 - accuracy: 0.8160 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5292 - val_accuracy: 0.7188\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 1363/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4075 - accuracy: 0.8177 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8177 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4074 - accuracy: 0.8194 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8212 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5296 - val_accuracy: 0.7188\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5296 - val_accuracy: 0.7188\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8212 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4073 - accuracy: 0.8194 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8212 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8212 - val_loss: 0.5298 - val_accuracy: 0.7188\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8194 - val_loss: 0.5298 - val_accuracy: 0.7188\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8212 - val_loss: 0.5298 - val_accuracy: 0.7188\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5298 - val_accuracy: 0.7188\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8212 - val_loss: 0.5298 - val_accuracy: 0.7188\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8212 - val_loss: 0.5299 - val_accuracy: 0.7188\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8194 - val_loss: 0.5299 - val_accuracy: 0.7188\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8212 - val_loss: 0.5299 - val_accuracy: 0.7188\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8194 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4071 - accuracy: 0.8212 - val_loss: 0.5300 - val_accuracy: 0.7188\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8194 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5302 - val_accuracy: 0.7188\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4070 - accuracy: 0.8212 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4069 - accuracy: 0.8212 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1419/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4068 - accuracy: 0.8212 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5306 - val_accuracy: 0.7188\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8194 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5309 - val_accuracy: 0.7188\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8194 - val_loss: 0.5309 - val_accuracy: 0.7188\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.8212 - val_loss: 0.5310 - val_accuracy: 0.7188\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5311 - val_accuracy: 0.7188\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.5311 - val_accuracy: 0.7240\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8194 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4066 - accuracy: 0.8194 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8229 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4066 - accuracy: 0.8212 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8229 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4064 - accuracy: 0.8194 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4065 - accuracy: 0.8212 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5315 - val_accuracy: 0.7240\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8229 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8229 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8229 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 1475/1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8229 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8229 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8194 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4063 - accuracy: 0.8212 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5320 - val_accuracy: 0.7240\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5320 - val_accuracy: 0.7240\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5320 - val_accuracy: 0.7240\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4062 - accuracy: 0.8212 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5323 - val_accuracy: 0.7240\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5323 - val_accuracy: 0.7240\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8212 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8194 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4060 - accuracy: 0.8212 - val_loss: 0.5323 - val_accuracy: 0.7240\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.641\n",
      "roc-auc is 0.802\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "y_pred_class_nn_2 = np.argmax(y_pred_prob_nn_2, axis = 1)\n",
    "\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
